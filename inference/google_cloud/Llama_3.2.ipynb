{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "# Chat completions API\n",
    "import openai\n",
    "from google.auth import default, transport\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "PROJECT_ID = \"mimetic-kit-445917-d8\" \n",
    "# Only `us-central1` is supported region for Llama 3.2 models using Model-as-a-Service (MaaS).\n",
    "LOCATION = \"us-central1\"\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "credentials, _ = default()\n",
    "auth_request = transport.requests.Request()\n",
    "credentials.refresh(auth_request)\n",
    "\n",
    "MODEL_LOCATION = \"us-central1\"\n",
    "MAAS_ENDPOINT = f\"{MODEL_LOCATION}-aiplatform.googleapis.com\"\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
    "    api_key=credentials.token,\n",
    ")\n",
    "\n",
    "MODEL_ID = \"meta/llama-3.2-90b-vision-instruct-maas\"  # @param {type:\"string\"} [\"meta/llama-3.2-90b-vision-instruct-maas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "# Chat completions API\n",
    "import openai\n",
    "from google.auth import default, transport\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_image_from_bucket(bucket_name: str, blob_name: str) -> None:\n",
    "    \"\"\"Visualizes an image stored in a Google Cloud Storage bucket.\"\"\"\n",
    "    try:\n",
    "        # Create a client for interacting with Google Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "\n",
    "        # Get a reference to the bucket and blob\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download the image data into memory\n",
    "        image_data = blob.download_as_bytes()\n",
    "\n",
    "        # Open the image using PIL\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "        # Display the image using matplotlib\n",
    "        plt.figure(figsize=(10, 10))  # Set the figure size (adjust as needed)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")  # Turn off axis labels\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing image: {e}\")\n",
    "        \n",
    "def encode_image_to_base64(file_path):\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "        base64_image = base64.b64encode(image_data).decode('utf-8')\n",
    "        return f\"data:image/jpeg;base64,{base64_image}\"\n",
    "      \n",
    "def create_collage(image_paths, output_path):\n",
    "    images = [Image.open(img) for img in image_paths]\n",
    "    width, height = images[0].size\n",
    "\n",
    "    # Combine images horizontally\n",
    "    collage = Image.new(\"RGB\", (width * len(images), height))\n",
    "    for i, img in enumerate(images):\n",
    "        collage.paste(img, (i * width, 0))\n",
    "\n",
    "    collage.save(output_path)\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a 3D bar graph with a red and blue color scheme. The graph features a single bar that is divided into two sections, with the top section being blue and the bottom section being red. The bar is positioned at an angle, with the top section pointing towards the upper left corner of the image and the bottom section pointing towards the lower right corner.\n",
      "\n",
      "To the left of the bar, there is a small red and blue triangle that appears to be a legend or key for the graph. The triangle is oriented in the same direction as the bar, with the red section at the bottom and the blue section at the top.\n",
      "\n",
      "The background of the image is white, which helps to make the colors of the bar and triangle stand out. Overall, the image presents a clear and concise visual representation of data, with the use of color and orientation helping to convey meaning and context.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.There are 3 variables: \n",
    "1. neddle_position\n",
    "2. magnetic_bar_direction\n",
    "3. neddle_direction\n",
    ".\n",
    "Please fill this causality adjacency matrix:\n",
    "[[_, _, _]\n",
    " [_, _, _]\n",
    " [_, _, _]].\n",
    "In the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "\"\"\"\n",
    "\n",
    "image_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_004627_Over_3D_128p.png\"\n",
    "# Getting the base64 string\n",
    "\n",
    "\n",
    "image_paths = [image_path]\n",
    "output_path = \"./collage.png\"\n",
    "create_collage(image_paths, output_path)\n",
    "with open(output_path, \"rb\") as image_file:\n",
    "    base64_collage = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "prompt = \"what do you see in the images\"\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"image_url\": {\"url\": \"data:image/png;base64,\" + base64_collage}, \"type\": \"image_url\"},\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=max_tokens,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
