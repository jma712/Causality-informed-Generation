{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[refernece](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal?hl=zh-cn#python)  \n",
    "[colab](https://console.cloud.google.com/vertex-ai/colab/notebooks?project=linen-flash-428508-h4&hl=en&supportedpurview=project&activeNb=projects%2Flinen-flash-428508-h4%2Flocations%2Fus-central1%2Frepositories%2F930bb123-178f-4a38-b77a-c1c5e7341480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U -q google-cloud-aiplatform[evaluation]\n",
    "!pip install -U -q datasets\n",
    "!pip install -U -q anthropic[vertex]\n",
    "!pip install -U -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import HTML, Markdown, display\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"mimetic-kit-445917-d8\"\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    raise ValueError(\"Please set your PROJECT_ID\")\n",
    "\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "from anthropic import AnthropicVertex\n",
    "from google.auth import default, transport\n",
    "import openai\n",
    "from vertexai.evaluation import (\n",
    "    EvalTask,\n",
    "    MetricPromptTemplateExamples,\n",
    "    PairwiseMetric,\n",
    "    PointwiseMetric,\n",
    "    PointwiseMetricPromptTemplate,\n",
    ")\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "import vertexai\n",
    "\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-002\",\n",
    "    generation_config={\"temperature\": 0.6, \"max_output_tokens\": 256, \"top_k\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Model Response: </h2><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The causal relationships are as follows:\n",
       "\n",
       "1. **Weight of the cube causes a change in the length of the spring.**  A heavier cube will compress the spring more, resulting in a shorter length. A lighter cube will compress the spring less, resulting in a longer length.\n",
       "\n",
       "2. **The spring constant influences the length of the spring.** A higher spring constant means the spring is stiffer and will compress less for a given weight, resulting in a longer length. A lower spring constant means the spring is less stiff and will compress more for a given weight, resulting in a shorter length.\n",
       "\n",
       "3. **Neither the spring length nor the spring constant affect the weight of the cube.** The cube's weight is an independent variable.\n",
       "\n",
       "\n",
       "Therefore, the causal adjacency matrix is:\n",
       "\n",
       "```\n",
       "[[0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 0]]\n",
       "```\n",
       "\n",
       "Where:\n",
       "\n",
       "* Row 1: Weight of the cube\n",
       "* Row 2: Spring constant\n",
       "* Row 3: Length of the spring\n",
       "\n",
       "\n",
       "This matrix representation indicates that the weight (row 1) and spring constant (row 2) both cause a change in the spring length (column 3)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "# Read the local image\n",
    "local_image_path = \"/home/lds/github/Causality-informed-Generation/20241216_004722.png\"\n",
    "system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships, highlighting key features or patterns that support your conclusions.\"\n",
    "scene_info = \"There are 3 variables: 1. the weight of cube, 2. the spring constant, and 3. the lenght of spring.You try to fill this causal adjacency matrix.\"\n",
    "matrix = \"[[_, _, _], [_ , _, _], [_ , _, _]]\"\n",
    "matrix_info = \"in the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "\n",
    "\n",
    "response = model.generate_content(\n",
    "    [\n",
    "        Part.from_image(Image.load_from_file(local_image_path)),\n",
    "        Part.from_image(Image.load_from_file(local_image_path)),\n",
    "        Part.from_image(Image.load_from_file(local_image_path)),\n",
    "        Part.from_image(Image.load_from_file(local_image_path)),\n",
    "        Part.from_image(Image.load_from_file(local_image_path)),\n",
    "        Part.from_text(system_info + scene_info + matrix + matrix_info),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "display(HTML(\"<h2>Model Response: </h2><hr>\"))\n",
    "Markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matrix(text):\n",
    "  first_index = text.find(\"```\")\n",
    "  final_index = text.rfind(\"```\")\n",
    "  # print(text[first_index+3:final_index])\n",
    "  if first_index == -1 or final_index == -1:\n",
    "    raise ValueError(\"Matrix not found in the response\")\n",
    "    return None\n",
    "  matrix = eval(text[first_index+3:final_index])\n",
    "  return matrix\n",
    " \n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def Gemini_infer(setting, csv_file=\"gemini_inference_log.csv\"):\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(\"Gemini_infer\")\n",
    "\n",
    "    # Initialize model with flexible configuration\n",
    "    model = GenerativeModel(\n",
    "        setting.get(\"model_name\", \"default-model-name\"),\n",
    "        generation_config=setting.get(\"generation_config\", {\"temperature\": 1, \"max_output_tokens\": 1000, \"top_k\": 1}),\n",
    "    )\n",
    "\n",
    "    # Load images\n",
    "    imgs = [Part.from_image(Image.load_from_file(path)) for path in setting[\"image_path\"]]\n",
    "    # logger.info(\"Loaded images: %s\", setting[\"image_path\"])\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = imgs + [Part.from_text(\n",
    "        setting[\"system_info\"] +\n",
    "        setting[\"scene_info\"] +\n",
    "        setting[\"matrix\"] +\n",
    "        setting[\"matrix_info\"]\n",
    "    )]\n",
    "    text_prompt = setting[\"system_info\"] + setting[\"scene_info\"] + setting[\"matrix\"] + setting[\"matrix_info\"]\n",
    "    # Log the prompt for debugging\n",
    "    # logger.info(\"Generated Prompt: %s\", prompt)\n",
    "\n",
    "    # Generate response\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Model failed to generate content: %s\", str(e))\n",
    "        raise\n",
    "\n",
    "    # Log the response for debugging\n",
    "    # logger.info(\"Model Response: %s\", response.text)\n",
    "\n",
    "    # Extract matrix\n",
    "    try:\n",
    "        matrix = extract_matrix(response.text)\n",
    "    except ValueError as e:\n",
    "        logger.error(\"Matrix extraction failed: %s\", str(e))\n",
    "        raise\n",
    "\n",
    "    # Log settings, prompt, response, and matrix\n",
    "    # logger.info(\"Settings: %s\", setting)\n",
    "    # logger.info(\"Extracted Matrix: %s\", matrix)\n",
    "\n",
    "    # Get the current timestamp\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    headers = [\"time\", \"imgs\", \"text_prompt\", \"response\", \"matrix\"]\n",
    "    row = {\n",
    "        \"time\": current_time,\n",
    "        \"imgs\": str(setting[\"image_path\"]),\n",
    "        \"text_prompt\": str(text_prompt),\n",
    "        \"response\": response.text,\n",
    "        \"matrix\": str(matrix),\n",
    "    }\n",
    "\n",
    "    # Ensure the CSV file is created with headers if it doesn't exist\n",
    "    try:\n",
    "        with open(csv_file, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=headers)\n",
    "            if file.tell() == 0:  # Write headers if the file is empty\n",
    "                writer.writeheader()\n",
    "            writer.writerow(row)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to write to CSV: %s\", str(e))\n",
    "        raise\n",
    "\n",
    "    return response.text, matrix\n",
    "  \n",
    "def compose_content(dict_info):\n",
    "  num_of_v = len(dict_info[\"variables\"])\n",
    "  variables = dict_info[\"variables\"]\n",
    "  content = ''\n",
    "  for i,v in enumerate(variables):\n",
    "    content += f\"{i+1}. {variables[v]}\\n\"\n",
    "  content = f\"There are {num_of_v} variables: \\n{content}.\\n\" \n",
    "  content += \"Please fill this causality adjacency matrix:\\n\"\n",
    "  return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### magnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'magnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m scene_info_dict \u001b[38;5;241m=\u001b[39m scene\u001b[38;5;241m.\u001b[39mget_scene(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMagnets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m magnet_img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[43mmagnet\u001b[49m)\n\u001b[1;32m     15\u001b[0m files \u001b[38;5;241m=\u001b[39m [magnet_img_path \u001b[38;5;241m+\u001b[39m file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# randomly pick 10 images\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'magnet' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "from utils import evaluation\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"Magnets\")\n",
    "\n",
    "magnet_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/\"\n",
    "\n",
    "files = os.listdir(magnet)\n",
    "files = [magnet_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_]')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"Magnets\")\n",
    "\n",
    "magnet_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/\"\n",
    "\n",
    "files = os.listdir(magnet)\n",
    "files = [magnet_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_]')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \" Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_magnet_basic.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cal_TPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the True Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    TPR = TP / (TP + FN)\n",
    "    \n",
    "    return TPR\n",
    "  \n",
    "def cal_FPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the False Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    TN = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 0))\n",
    "    FPR = FP / (FP + TN)\n",
    "    \n",
    "    return FPR\n",
    "  \n",
    "def cal_SHD_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Structural Hamming Distance between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    SHD = np.sum(ground_truth_matrix1 != matrix2)\n",
    "    \n",
    "    return SHD\n",
    "  \n",
    "def cal_Accuarcy_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Accuarcy between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    Accuarcy = np.sum(ground_truth_matrix1 == matrix2) / ground_truth_matrix1.size\n",
    "    \n",
    "    return Accuarcy\n",
    "  \n",
    "def cal_Precision_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Precision between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    if (TP + FP) == 0:\n",
    "      return 0\n",
    "    Precision = TP / (TP + FP)\n",
    "    \n",
    "    return Precision\n",
    "  \n",
    "def cal_Recall_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Recall between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    Recall = TP / (TP + FN)\n",
    "    \n",
    "    return Recall\n",
    "  \n",
    "def cal_F1_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the F1 between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "\n",
    "    if (TP + FP) == 0:\n",
    "      return 0\n",
    "    Precision = TP / (TP + FP)    \n",
    "\n",
    "    if (TP + FN) == 0:\n",
    "      return 0\n",
    "    Recall = TP / (TP + FN)\n",
    "    F1 = 2 * Precision * Recall / (Precision + Recall)\n",
    "    if (Precision + Recall) == 0:\n",
    "      return 0\n",
    "    \n",
    "    return F1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5)] \n",
      "TPR: 0.4864864864864865\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.0)] \n",
      "FPR: 0.011583011583011582\n",
      "[np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(4), np.int64(1)] \n",
      "SHD: 1.1081081081081081\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0)] \n",
      "Precision: 0.9594594594594594\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5)] \n",
      "Recall: 0.4864864864864865\n",
      "[np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.5555555555555556), np.float64(0.8888888888888888)] \n",
      "Accuracy: 0.8768768768768772\n",
      "[np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), 0, np.float64(0.6666666666666666)] \n",
      "F1: 0.6441441441441444\n"
     ]
    }
   ],
   "source": [
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5)] \n",
      "TPR: 0.4857142857142857\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.05306122448979591\n",
      "[np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(4), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(1), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(1)] \n",
      "SHD: 1.4\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.8142857142857143\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5)] \n",
      "Recall: 0.4857142857142857\n",
      "[np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.5555555555555556), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.8888888888888888)] \n",
      "Accuracy: 0.8444444444444448\n",
      "[np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), 0, np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666)] \n",
      "F1: 0.5952380952380953\n"
     ]
    }
   ],
   "source": [
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"reflection\")\n",
    "\n",
    "reflection_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/\"\n",
    "\n",
    "files = os.listdir(reflection_img_path)\n",
    "files = [reflection_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_reflection.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "TPR: 1.0\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.0\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] \n",
      "SHD: 0.0\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 1.0\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Recall: 1.0\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Accuracy: 1.0\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_reflection.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 1], [0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:49<00:12,  6.20s/it]ERROR:Gemini_infer:Model failed to generate content: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\n",
      " 80%|████████  | 8/10 [00:49<00:12,  6.23s/it]\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.191.106:443 {created_time:\"2025-01-03T00:00:24.410229075-05:00\", grpc_status:8, grpc_message:\"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[382], line 34\u001b[0m\n\u001b[1;32m     22\u001b[0m   system_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m   setting \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m : imgs_path,\n\u001b[1;32m     26\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_info\u001b[39m\u001b[38;5;124m\"\u001b[39m : system_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \n\u001b[1;32m     32\u001b[0m }\n\u001b[0;32m---> 34\u001b[0m   text, matrix \u001b[38;5;241m=\u001b[39m \u001b[43mGemini_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini_inference_log_spring.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[362], line 45\u001b[0m, in \u001b[0;36mGemini_infer\u001b[0;34m(setting, csv_file)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Log the prompt for debugging\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# logger.info(\"Generated Prompt: %s\", prompt)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     47\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel failed to generate content: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:619\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    611\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    612\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:744\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    736\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    737\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    738\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    743\u001b[0m )\n\u001b[0;32m--> 744\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2208\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2208\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"spring\")\n",
    "\n",
    "spring_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/\"\n",
    "\n",
    "files = os.listdir(spring_img_path)\n",
    "files = [spring_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_spring.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "TPR: 0.25\n",
      "[np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.42857142857142855), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.14285714285714285), np.float64(0.2857142857142857), np.float64(0.42857142857142855), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857)] \n",
      "FPR: 0.23214285714285707\n",
      "[np.int64(4), np.int64(4), np.int64(0), np.int64(0), np.int64(0), np.int64(5), np.int64(0), np.int64(4), np.int64(4), np.int64(4), np.int64(2), np.int64(4), np.int64(5), np.int64(4), np.int64(3), np.int64(4), np.int64(4), np.int64(4), np.int64(4), np.int64(0), np.int64(4), np.int64(4), np.int64(4), np.int64(4)] \n",
      "SHD: 3.125\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Precision: 0.24305555555555555\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Recall: 0.25\n",
      "[np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.4444444444444444), np.float64(1.0), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(0.7777777777777778), np.float64(0.5555555555555556), np.float64(0.4444444444444444), np.float64(0.5555555555555556), np.float64(0.6666666666666666), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(1.0), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(0.5555555555555556)] \n",
      "Accuracy: 0.6527777777777777\n",
      "[0, 0, np.float64(1.0), np.float64(1.0), np.float64(1.0), 0, np.float64(1.0), 0, 0, 0, np.float64(0.5), 0, 0, 0, np.float64(0.4), 0, 0, 0, 0, np.float64(1.0), 0, 0, 0, 0] \n",
      "F1: 0.24583333333333335\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_spring.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 1], [0, 0,1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"spring\")\n",
    "\n",
    "spring_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/\"\n",
    "\n",
    "files = os.listdir(spring_img_path)\n",
    "files = [spring_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_spring_basic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0)] \n",
      "TPR: 0.7763157894736842\n",
      "[np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.42857142857142855), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.42857142857142855), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.06766917293233081\n",
      "[np.int64(4), np.int64(0), np.int64(4), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(4), np.int64(5), np.int64(0), np.int64(4), np.int64(4), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(4), np.int64(5), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)] \n",
      "SHD: 0.9210526315789473\n",
      "[np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.7894736842105263\n",
      "[np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0)] \n",
      "Recall: 0.7763157894736842\n",
      "[np.float64(0.5555555555555556), np.float64(1.0), np.float64(0.5555555555555556), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5555555555555556), np.float64(0.4444444444444444), np.float64(1.0), np.float64(0.5555555555555556), np.float64(0.5555555555555556), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5555555555555556), np.float64(0.4444444444444444), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8888888888888888), np.float64(1.0)] \n",
      "Accuracy: 0.8976608187134504\n",
      "[0, np.float64(1.0), 0, np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), 0, 0, np.float64(1.0), 0, 0, np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), 0, 0, np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(1.0)] \n",
      "F1: 0.7807017543859649\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_spring_basic.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 1], [0, 0,1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seesaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"Seesaw\")\n",
    "\n",
    "seesaw_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_seesaw_128P/\"\n",
    "\n",
    "files = os.listdir(seesaw_img_path)\n",
    "files = [seesaw_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_seesaw_basic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5)] \n",
      "TPR: 0.5\n",
      "[np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.02857142857142857\n",
      "[np.int64(2), np.int64(4), np.int64(2), np.int64(4), np.int64(2), np.int64(2), np.int64(4), np.int64(2), np.int64(2), np.int64(2)] \n",
      "SHD: 2.6\n",
      "[np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.85\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5)] \n",
      "Recall: 0.5\n",
      "[np.float64(0.92), np.float64(0.84), np.float64(0.92), np.float64(0.84), np.float64(0.92), np.float64(0.92), np.float64(0.84), np.float64(0.92), np.float64(0.92), np.float64(0.92)] \n",
      "Accuracy: 0.8960000000000001\n",
      "[np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666)] \n",
      "F1: 0.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_seesaw_basic.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0)] \n",
      "TPR: 0.7407407407407407\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.01763668430335097\n",
      "[np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(4), np.int64(2), np.int64(0), np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(0), np.int64(4), np.int64(2), np.int64(4), np.int64(0), np.int64(0), np.int64(0), np.int64(2), np.int64(2), np.int64(0), np.int64(4), np.int64(4), np.int64(0), np.int64(2), np.int64(2), np.int64(0)] \n",
      "SHD: 1.4074074074074074\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.9074074074074074\n",
      "[np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0)] \n",
      "Recall: 0.7407407407407407\n",
      "[np.float64(0.92), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.84), np.float64(0.92), np.float64(1.0), np.float64(1.0), np.float64(0.92), np.float64(0.92), np.float64(1.0), np.float64(1.0), np.float64(0.84), np.float64(0.92), np.float64(0.84), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.92), np.float64(0.92), np.float64(1.0), np.float64(0.84), np.float64(0.84), np.float64(1.0), np.float64(0.92), np.float64(0.92), np.float64(1.0)] \n",
      "Accuracy: 0.9437037037037038\n",
      "[np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0)] \n",
      "F1: 0.7962962962962963\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_seesaw.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"P_refraction\")\n",
    "\n",
    "transmission_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/\"\n",
    "\n",
    "files = os.listdir(transmission_img_path)\n",
    "files = [transmission_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_transmission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "TPR: 0.9595959595959597\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.15384615384615385), np.float64(0.07692307692307693), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.009324009324009324\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(2), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] \n",
      "SHD: 0.24242424242424243\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.75), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.9671717171717172\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Recall: 0.9595959595959597\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.9375), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.9375), np.float64(0.9375), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8125), np.float64(0.875), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Accuracy: 0.9848484848484849\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8571428571428571), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8), np.float64(0.8), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5714285714285715), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "F1: 0.9604617604617606\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_transmission.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prism reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"P_reflection\")\n",
    "\n",
    "prism_reflection_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/\"\n",
    "\n",
    "files = os.listdir(prism_reflection_img_path)\n",
    "files = [prism_reflection_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_P_reflection.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.0), np.float64(1.0)] \n",
      "TPR: 0.7261904761904762\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.15384615384615385), np.float64(0.0), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.07692307692307693), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.15384615384615385), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.23076923076923078), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.15384615384615385), np.float64(0.07692307692307693), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.0), np.float64(0.23076923076923078), np.float64(0.15384615384615385)] \n",
      "FPR: 0.09615384615384615\n",
      "[np.int64(1), np.int64(0), np.int64(1), np.int64(3), np.int64(1), np.int64(3), np.int64(2), np.int64(2), np.int64(2), np.int64(0), np.int64(2), np.int64(2), np.int64(4), np.int64(1), np.int64(1), np.int64(1), np.int64(5), np.int64(3), np.int64(2), np.int64(1), np.int64(2), np.int64(3), np.int64(1), np.int64(2), np.int64(4), np.int64(1), np.int64(6), np.int64(2)] \n",
      "SHD: 2.0714285714285716\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(0.5), np.float64(0.6), np.float64(0.6), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.75), np.float64(0.75), np.float64(0.25), np.float64(0.5), np.float64(0.6), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.75), np.float64(0.6), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.0), np.float64(0.6)] \n",
      "Precision: 0.6726190476190476\n",
      "[np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.0), np.float64(1.0)] \n",
      "Recall: 0.7261904761904762\n",
      "[np.float64(0.9375), np.float64(1.0), np.float64(0.9375), np.float64(0.8125), np.float64(0.9375), np.float64(0.8125), np.float64(0.875), np.float64(0.875), np.float64(0.875), np.float64(1.0), np.float64(0.875), np.float64(0.875), np.float64(0.75), np.float64(0.9375), np.float64(0.9375), np.float64(0.9375), np.float64(0.6875), np.float64(0.8125), np.float64(0.875), np.float64(0.9375), np.float64(0.875), np.float64(0.8125), np.float64(0.9375), np.float64(0.875), np.float64(0.75), np.float64(0.9375), np.float64(0.625), np.float64(0.875)] \n",
      "Accuracy: 0.8705357142857143\n",
      "[np.float64(0.8), np.float64(1.0), np.float64(0.8), np.float64(0.5714285714285715), np.float64(0.8), np.float64(0.5714285714285715), np.float64(0.7499999999999999), np.float64(0.7499999999999999), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.8), np.float64(0.8571428571428571), np.float64(0.8571428571428571), np.float64(0.28571428571428575), np.float64(0.5714285714285715), np.float64(0.7499999999999999), np.float64(0.8), np.float64(0.6666666666666666), np.float64(0.5714285714285715), np.float64(0.8571428571428571), np.float64(0.7499999999999999), np.float64(0.3333333333333333), np.float64(0.8), 0, np.float64(0.7499999999999999)] \n",
      "F1: 0.6795068027210885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/2682095722.py:103: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_P_reflection.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypythetical v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"3_V\")\n",
    "\n",
    "h3_linear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h3_128P/\"\n",
    "\n",
    "files = os.listdir(h3_linear_img_path)\n",
    "files = [h3_linear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h3_linear.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)] \n",
      "TPR: 0.37500000000000006\n",
      "[np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.046875\n",
      "[np.int64(2), np.int64(5), np.int64(2), np.int64(5), np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(4), np.int64(5), np.int64(2), np.int64(2), np.int64(3), np.int64(1), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(3), np.int64(2), np.int64(2)] \n",
      "SHD: 2.15625\n",
      "[np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.84375\n",
      "[np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333)] \n",
      "Recall: 0.37500000000000006\n",
      "[np.float64(0.7777777777777778), np.float64(0.4444444444444444), np.float64(0.7777777777777778), np.float64(0.4444444444444444), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.5555555555555556), np.float64(0.4444444444444444), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.6666666666666666), np.float64(0.8888888888888888), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.6666666666666666), np.float64(0.7777777777777778), np.float64(0.7777777777777778)] \n",
      "Accuracy: 0.760416666666667\n",
      "[np.float64(0.5), 0, np.float64(0.5), 0, np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.8), np.float64(0.5), np.float64(0.8), np.float64(0.5), np.float64(0.8), np.float64(0.5), 0, 0, np.float64(0.5), np.float64(0.5), np.float64(0.4), np.float64(0.8), np.float64(0.8), np.float64(0.5), np.float64(0.5), np.float64(0.8), np.float64(0.5), np.float64(0.8), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.8), np.float64(0.4), np.float64(0.5), np.float64(0.5)] \n",
      "F1: 0.5062500000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/3887620691.py:108: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h3_linear.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.6666666666666666), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "TPR: 0.15151515151515152\n",
      "[np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.3333333333333333), np.float64(0.16666666666666666), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.16666666666666666)] \n",
      "FPR: 0.1818181818181818\n",
      "[np.int64(2), np.int64(4), np.int64(3), np.int64(5), np.int64(1), np.int64(5), np.int64(5), np.int64(5), np.int64(5), np.int64(2), np.int64(3), np.int64(2), np.int64(2), np.int64(2), np.int64(4), np.int64(3), np.int64(4), np.int64(5), np.int64(4), np.int64(5), np.int64(5), np.int64(4)] \n",
      "SHD: 3.6363636363636362\n",
      "[np.float64(1.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Precision: 0.3409090909090909\n",
      "[np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.6666666666666666), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Recall: 0.15151515151515152\n",
      "[np.float64(0.7777777777777778), np.float64(0.5555555555555556), np.float64(0.6666666666666666), np.float64(0.4444444444444444), np.float64(0.8888888888888888), np.float64(0.4444444444444444), np.float64(0.4444444444444444), np.float64(0.4444444444444444), np.float64(0.4444444444444444), np.float64(0.7777777777777778), np.float64(0.6666666666666666), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.5555555555555556), np.float64(0.6666666666666666), np.float64(0.5555555555555556), np.float64(0.4444444444444444), np.float64(0.5555555555555556), np.float64(0.4444444444444444), np.float64(0.4444444444444444), np.float64(0.5555555555555556)] \n",
      "Accuracy: 0.595959595959596\n",
      "[np.float64(0.5), 0, np.float64(0.4), 0, np.float64(0.8), 0, 0, 0, 0, np.float64(0.5), np.float64(0.4), np.float64(0.5), np.float64(0.5), np.float64(0.5), 0, np.float64(0.4), 0, 0, 0, 0, 0, 0] \n",
      "F1: 0.20454545454545456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/3887620691.py:108: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h3_linear_basic.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothetic v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:29<00:00,  8.99s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"4_V\")\n",
    "\n",
    "h4_linear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h4_100x256/\"\n",
    "\n",
    "files = os.listdir(h4_linear_img_path)\n",
    "files = [h4_linear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h4_linear.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:30<00:00,  9.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"4_V\")\n",
    "\n",
    "h4_linear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h4_100x256/\"\n",
    "\n",
    "files = os.listdir(h4_linear_img_path)\n",
    "files = [h4_linear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h4_linear_base.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.2), np.float64(0.2)] \n",
      "TPR: 0.15999999999999998\n",
      "[np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.0), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091)] \n",
      "FPR: 0.08181818181818183\n",
      "[np.int64(5), np.int64(5), np.int64(5), np.int64(4), np.int64(6), np.int64(5), np.int64(6), np.int64(5), np.int64(5), np.int64(5)] \n",
      "SHD: 5.1\n",
      "[np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(1.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.5)] \n",
      "Precision: 0.45\n",
      "[np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.2), np.float64(0.2)] \n",
      "Recall: 0.15999999999999998\n",
      "[np.float64(0.6875), np.float64(0.6875), np.float64(0.6875), np.float64(0.75), np.float64(0.625), np.float64(0.6875), np.float64(0.625), np.float64(0.6875), np.float64(0.6875), np.float64(0.6875)] \n",
      "Accuracy: 0.68125\n",
      "[np.float64(0.28571428571428575), np.float64(0.28571428571428575), np.float64(0.28571428571428575), np.float64(0.33333333333333337), 0, np.float64(0.28571428571428575), 0, np.float64(0.28571428571428575), np.float64(0.28571428571428575), np.float64(0.28571428571428575)] \n",
      "F1: 0.23333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/3887620691.py:108: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h4_linear_base.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.6), np.float64(0.0), np.float64(0.4), np.float64(0.2), np.float64(0.6), np.float64(0.6), np.float64(0.6), np.float64(0.2), np.float64(0.2), np.float64(0.6), np.float64(0.2), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.6), np.float64(0.0), np.float64(0.2), np.float64(0.6), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.6), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.4)] \n",
      "TPR: 0.23870967741935484\n",
      "[np.float64(0.0), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.0), np.float64(0.0), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.0), np.float64(0.0), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.18181818181818182), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.0)] \n",
      "FPR: 0.07624633431085041\n",
      "[np.int64(4), np.int64(6), np.int64(5), np.int64(6), np.int64(3), np.int64(6), np.int64(3), np.int64(4), np.int64(3), np.int64(3), np.int64(3), np.int64(4), np.int64(4), np.int64(3), np.int64(5), np.int64(5), np.int64(6), np.int64(6), np.int64(3), np.int64(6), np.int64(5), np.int64(3), np.int64(6), np.int64(6), np.int64(6), np.int64(3), np.int64(5), np.int64(7), np.int64(6), np.int64(6), np.int64(3)] \n",
      "SHD: 4.645161290322581\n",
      "[np.float64(1.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.75), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(1.0), np.float64(1.0), np.float64(0.75), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.75), np.float64(0.0), np.float64(0.5), np.float64(0.75), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.75), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0)] \n",
      "Precision: 0.46774193548387094\n",
      "[np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.6), np.float64(0.0), np.float64(0.4), np.float64(0.2), np.float64(0.6), np.float64(0.6), np.float64(0.6), np.float64(0.2), np.float64(0.2), np.float64(0.6), np.float64(0.2), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.6), np.float64(0.0), np.float64(0.2), np.float64(0.6), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.6), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.4)] \n",
      "Recall: 0.23870967741935484\n",
      "[np.float64(0.75), np.float64(0.625), np.float64(0.6875), np.float64(0.625), np.float64(0.8125), np.float64(0.625), np.float64(0.8125), np.float64(0.75), np.float64(0.8125), np.float64(0.8125), np.float64(0.8125), np.float64(0.75), np.float64(0.75), np.float64(0.8125), np.float64(0.6875), np.float64(0.6875), np.float64(0.625), np.float64(0.625), np.float64(0.8125), np.float64(0.625), np.float64(0.6875), np.float64(0.8125), np.float64(0.625), np.float64(0.625), np.float64(0.625), np.float64(0.8125), np.float64(0.6875), np.float64(0.5625), np.float64(0.625), np.float64(0.625), np.float64(0.8125)] \n",
      "Accuracy: 0.7096774193548387\n",
      "[np.float64(0.33333333333333337), 0, np.float64(0.28571428571428575), 0, np.float64(0.6666666666666665), 0, np.float64(0.5714285714285715), np.float64(0.33333333333333337), np.float64(0.6666666666666665), np.float64(0.6666666666666665), np.float64(0.6666666666666665), np.float64(0.33333333333333337), np.float64(0.33333333333333337), np.float64(0.6666666666666665), np.float64(0.28571428571428575), np.float64(0.28571428571428575), 0, 0, np.float64(0.6666666666666665), 0, np.float64(0.28571428571428575), np.float64(0.6666666666666665), 0, 0, 0, np.float64(0.6666666666666665), np.float64(0.28571428571428575), 0, 0, 0, np.float64(0.5714285714285715)] \n",
      "F1: 0.2980030721966205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/3887620691.py:108: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h4_linear.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyothetical V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:54<00:00, 11.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"5_V\")\n",
    "h5_linear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h5_200x100/\"\n",
    "\n",
    "files = os.listdir(h5_linear_img_path)\n",
    "files = [h5_linear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h5_linear.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "TPR: 0.03571428571428571\n",
      "[np.float64(0.16666666666666666), np.float64(0.2222222222222222), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.16666666666666666), np.float64(0.0), np.float64(0.1111111111111111), np.float64(0.0), np.float64(0.2222222222222222), np.float64(0.16666666666666666), np.float64(0.2222222222222222), np.float64(0.1111111111111111), np.float64(0.16666666666666666), np.float64(0.1111111111111111), np.float64(0.16666666666666666), np.float64(0.1111111111111111), np.float64(0.16666666666666666), np.float64(0.1111111111111111), np.float64(0.1111111111111111)] \n",
      "FPR: 0.13333333333333333\n",
      "[np.int64(9), np.int64(11), np.int64(9), np.int64(9), np.int64(9), np.int64(9), np.int64(6), np.int64(9), np.int64(6), np.int64(10), np.int64(10), np.int64(11), np.int64(9), np.int64(10), np.int64(9), np.int64(10), np.int64(9), np.int64(10), np.int64(9), np.int64(9)] \n",
      "SHD: 9.15\n",
      "[np.float64(0.25), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.25), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Precision: 0.135\n",
      "[np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Recall: 0.03571428571428571\n",
      "[np.float64(0.64), np.float64(0.56), np.float64(0.64), np.float64(0.64), np.float64(0.64), np.float64(0.64), np.float64(0.76), np.float64(0.64), np.float64(0.76), np.float64(0.6), np.float64(0.6), np.float64(0.56), np.float64(0.64), np.float64(0.6), np.float64(0.64), np.float64(0.6), np.float64(0.64), np.float64(0.6), np.float64(0.64), np.float64(0.64)] \n",
      "Accuracy: 0.6340000000000001\n",
      "[np.float64(0.18181818181818182), 0, 0, 0, 0, np.float64(0.18181818181818182), np.float64(0.25), 0, np.float64(0.25), np.float64(0.16666666666666666), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "F1: 0.051515151515151514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/3887620691.py:108: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h5_linear.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:58<00:00, 11.84s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "\n",
    "scene = info.scene()\n",
    "scene_info_dict = scene.get_scene(\"5_V\")\n",
    "h5_linear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h5_200x100/\"\n",
    "\n",
    "files = os.listdir(h5_linear_img_path)\n",
    "files = [h5_linear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h5_linear_base.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0)] \n",
      "TPR: 0.06285714285714285\n",
      "[np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.16666666666666666), np.float64(0.05555555555555555), np.float64(0.2777777777777778), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.05555555555555555), np.float64(0.2777777777777778), np.float64(0.05555555555555555), np.float64(0.0), np.float64(0.05555555555555555), np.float64(0.16666666666666666), np.float64(0.05555555555555555), np.float64(0.1111111111111111), np.float64(0.2777777777777778), np.float64(0.1111111111111111), np.float64(0.05555555555555555), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.05555555555555555), np.float64(0.05555555555555555)] \n",
      "FPR: 0.10222222222222221\n",
      "[np.int64(7), np.int64(8), np.int64(9), np.int64(8), np.int64(12), np.int64(8), np.int64(7), np.int64(8), np.int64(9), np.int64(9), np.int64(8), np.int64(11), np.int64(7), np.int64(6), np.int64(8), np.int64(9), np.int64(8), np.int64(7), np.int64(11), np.int64(9), np.int64(8), np.int64(9), np.int64(8), np.int64(8), np.int64(8)] \n",
      "SHD: 8.4\n",
      "[np.float64(0.5), np.float64(0.0), np.float64(0.25), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.5), np.float64(1.0), np.float64(0.0), np.float64(0.25), np.float64(0.0), np.float64(0.5), np.float64(0.16666666666666666), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0)] \n",
      "Precision: 0.16666666666666669\n",
      "[np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0)] \n",
      "Recall: 0.06285714285714285\n",
      "[np.float64(0.72), np.float64(0.68), np.float64(0.64), np.float64(0.68), np.float64(0.52), np.float64(0.68), np.float64(0.72), np.float64(0.68), np.float64(0.64), np.float64(0.64), np.float64(0.68), np.float64(0.56), np.float64(0.72), np.float64(0.76), np.float64(0.68), np.float64(0.64), np.float64(0.68), np.float64(0.72), np.float64(0.56), np.float64(0.64), np.float64(0.68), np.float64(0.64), np.float64(0.68), np.float64(0.68), np.float64(0.68)] \n",
      "Accuracy: 0.664\n",
      "[np.float64(0.22222222222222224), 0, np.float64(0.18181818181818182), 0, 0, 0, np.float64(0.22222222222222224), 0, 0, 0, 0, np.float64(0.15384615384615383), np.float64(0.22222222222222224), np.float64(0.25), 0, np.float64(0.18181818181818182), 0, np.float64(0.36363636363636365), np.float64(0.15384615384615383), 0, 0, 0, np.float64(0.2), 0, 0] \n",
      "F1: 0.08606526806526807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/3887620691.py:108: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h5_linear_base.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothetic v2 -- Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:24<00:10,  3.52s/it]ERROR:Gemini_infer:Model failed to generate content: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\n",
      " 70%|███████   | 7/10 [00:24<00:10,  3.53s/it]\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.191.106:443 {created_time:\"2025-01-03T01:58:49.663715931-05:00\", grpc_status:8, grpc_message:\"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 101\u001b[0m\n\u001b[1;32m     89\u001b[0m   system_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m   setting \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     92\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m : imgs_path,\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_info\u001b[39m\u001b[38;5;124m\"\u001b[39m : system_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m   \n\u001b[1;32m     99\u001b[0m }\n\u001b[0;32m--> 101\u001b[0m   text, matrix \u001b[38;5;241m=\u001b[39m \u001b[43mGemini_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini_inference_log_h2_nonlinear_base.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 43\u001b[0m, in \u001b[0;36mGemini_infer\u001b[0;34m(setting, csv_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Log the prompt for debugging\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# logger.info(\"Generated Prompt: %s\", prompt)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     45\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel failed to generate content: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:619\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    611\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    612\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:744\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    736\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    737\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    738\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    743\u001b[0m )\n\u001b[0;32m--> 744\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2208\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2208\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "import numpy as np\n",
    "\n",
    "class scene:\n",
    "  def __init__(self,):\n",
    "    self.scenes = {\n",
    "      \"reflection\": {\n",
    "        #![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Reflection_circle_320x320.png)\n",
    "        \"variables\": {0: \"incident_degree\", 1: \"reflection_degree\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1], [0, 0]])\n",
    "      },\n",
    "      \"spring\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Spring.png)\n",
    "        \"variables\": {0: \"spring_constant\", 1: \"weight\", 2: \"defomation\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1],[0,0,1],[0,0,0]])\n",
    "      },\n",
    "      \"Seesaw\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241120_150057.png)\n",
    "        \"variables\": {0: \"seesaw_left_arm\", 1: \"left_weight\", 2: \"seesaw_right_arm\", 3: \"right_weight\", 4: \"seesaw_torque\"},\n",
    "        \"variables_2\": {0: \"left_force\", 1: \"right_force\", 2: \"seesaw_torque\"},\n",
    "        \"adjacency_matrix_2\": np.array([[0,0,1],[0,0,1],[0,0,0]]),\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1],\n",
    "                                        [0, 0, 0, 0, 0]])\n",
    "      },\n",
    "      \"Magnets\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241123_161201_Over_3D_256p.png)\n",
    "        \"variables\": {0: \"neddle_position\", 1: \"magnetic_bar_direction\", 2: \"neddle_direction\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0 , 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/Yellow%20(570-590%20nm)_20241201_100615.png)\n",
    "      \"P_reflection\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"reflected_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/1732947800.585619_rendered_image.png)\n",
    "      \"P_refraction\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"refracted_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      \"3_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"v_cylinder\", 2: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \"4_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "      },\n",
    "      \"5_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\", 4: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"2_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of cylinder\", 1: \"volumn of ball\"},\n",
    "        # b = cos(a) + 5 * epsilon\n",
    "        \"adjacency_matrix\": np.array([[0,1],[0,0]])\n",
    "      },\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "  def get_all_scenes(self):\n",
    "    return self.scenes\n",
    "  \n",
    "  def get_scencs_name(self):\n",
    "    return self.scenes.keys()\n",
    "  \n",
    "  def get_scene(self, scene_name):\n",
    "    return self.scenes[scene_name]\n",
    "\n",
    "scene = scene()\n",
    "scene_info_dict = scene.get_scene(\"2_V_nonlinear\")\n",
    "h2_nonlinear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h2_nonlinear_128P/\"\n",
    "\n",
    "files = os.listdir(h2_nonlinear_img_path)\n",
    "files = [h2_nonlinear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h2_nonlinear_base.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "TPR: 0.0\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.0\n",
      "[np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)] \n",
      "SHD: 1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Precision: 0.0\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Recall: 0.0\n",
      "[np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.75)] \n",
      "Accuracy: 0.75\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h2_nonlinear.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,1],[0,0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothetic v3 Nonlinear 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:59<00:00,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "import numpy as np\n",
    "\n",
    "class scene:\n",
    "  def __init__(self,):\n",
    "    self.scenes = {\n",
    "      \"reflection\": {\n",
    "        #![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Reflection_circle_320x320.png)\n",
    "        \"variables\": {0: \"incident_degree\", 1: \"reflection_degree\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1], [0, 0]])\n",
    "      },\n",
    "      \"spring\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Spring.png)\n",
    "        \"variables\": {0: \"spring_constant\", 1: \"weight\", 2: \"defomation\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1],[0,0,1],[0,0,0]])\n",
    "      },\n",
    "      \"Seesaw\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241120_150057.png)\n",
    "        \"variables\": {0: \"seesaw_left_arm\", 1: \"left_weight\", 2: \"seesaw_right_arm\", 3: \"right_weight\", 4: \"seesaw_torque\"},\n",
    "        \"variables_2\": {0: \"left_force\", 1: \"right_force\", 2: \"seesaw_torque\"},\n",
    "        \"adjacency_matrix_2\": np.array([[0,0,1],[0,0,1],[0,0,0]]),\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1],\n",
    "                                        [0, 0, 0, 0, 0]])\n",
    "      },\n",
    "      \"Magnets\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241123_161201_Over_3D_256p.png)\n",
    "        \"variables\": {0: \"neddle_position\", 1: \"magnetic_bar_direction\", 2: \"neddle_direction\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0 , 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/Yellow%20(570-590%20nm)_20241201_100615.png)\n",
    "      \"P_reflection\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"reflected_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/1732947800.585619_rendered_image.png)\n",
    "      \"P_refraction\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"refracted_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      \"3_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"v_cylinder\", 2: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \"4_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "      },\n",
    "      \"5_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\", 4: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"2_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of cylinder\", 1: \"volumn of ball\"},\n",
    "        # b = cos(a) + 5 * epsilon\n",
    "        \"adjacency_matrix\": np.array([[0,1],[0,0]])\n",
    "      },\n",
    "      \"3_V_nonlinear_1\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [1, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "      \"3_V_nonlinear_2\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "    }\n",
    "    \n",
    "  def get_all_scenes(self):\n",
    "    return self.scenes\n",
    "  \n",
    "  def get_scencs_name(self):\n",
    "    return self.scenes.keys()\n",
    "  \n",
    "  def get_scene(self, scene_name):\n",
    "    return self.scenes[scene_name]\n",
    "\n",
    "scene = scene()\n",
    "scene_info_dict = scene.get_scene(\"3_V_nonlinear_2\")\n",
    "h3_nonlinear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h3_nonlinear_1_128P/\"\n",
    "\n",
    "files = os.listdir(h3_nonlinear_img_path)\n",
    "files = [h3_nonlinear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h3_nonlinear_2_base.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.5)] \n",
      "TPR: 0.20689655172413793\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0)] \n",
      "FPR: 0.02463054187192118\n",
      "[np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(1), np.int64(2), np.int64(2), np.int64(2), np.int64(2), np.int64(1)] \n",
      "SHD: 1.7586206896551724\n",
      "[0, 0, 0, np.float64(1.0), 0, 0, 0, np.float64(0.5), 0, 0, 0, 0, 0, np.float64(1.0), np.float64(0.5), np.float64(1.0), 0, np.float64(1.0), np.float64(0.5), 0, np.float64(1.0), 0, 0, np.float64(1.0), np.float64(0.5), 0, 0, np.float64(0.5), np.float64(1.0)] \n",
      "Precision: 0.3275862068965517\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.5), np.float64(0.0), np.float64(0.0), np.float64(0.5), np.float64(0.5)] \n",
      "Recall: 0.20689655172413793\n",
      "[np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.7777777777777778), np.float64(0.8888888888888888)] \n",
      "Accuracy: 0.8045977011494256\n",
      "[0, 0, 0, np.float64(0.6666666666666666), 0, 0, 0, np.float64(0.5), 0, 0, 0, 0, 0, np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.6666666666666666), 0, np.float64(0.6666666666666666), np.float64(0.5), 0, np.float64(0.6666666666666666), 0, 0, np.float64(0.6666666666666666), np.float64(0.5), 0, 0, np.float64(0.5), np.float64(0.6666666666666666)] \n",
      "F1: 0.2471264367816092\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h3_nonlinear_2_base.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]ERROR:Gemini_infer:Model failed to generate content: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.190.106:443 {created_time:\"2025-01-03T03:03:37.954981858-05:00\", grpc_status:8, grpc_message:\"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 108\u001b[0m\n\u001b[1;32m     97\u001b[0m   system_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m   setting \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     99\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m : imgs_path,\n\u001b[1;32m    100\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_info\u001b[39m\u001b[38;5;124m\"\u001b[39m : system_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \n\u001b[1;32m    106\u001b[0m }\n\u001b[0;32m--> 108\u001b[0m   text, matrix \u001b[38;5;241m=\u001b[39m \u001b[43mGemini_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini_inference_log_h3_nonlinear_2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 43\u001b[0m, in \u001b[0;36mGemini_infer\u001b[0;34m(setting, csv_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Log the prompt for debugging\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# logger.info(\"Generated Prompt: %s\", prompt)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     45\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel failed to generate content: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:619\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    611\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    612\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:744\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    736\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    737\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    738\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    743\u001b[0m )\n\u001b[0;32m--> 744\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2208\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2208\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "import numpy as np\n",
    "\n",
    "class scene:\n",
    "  def __init__(self,):\n",
    "    self.scenes = {\n",
    "      \"reflection\": {\n",
    "        #![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Reflection_circle_320x320.png)\n",
    "        \"variables\": {0: \"incident_degree\", 1: \"reflection_degree\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1], [0, 0]])\n",
    "      },\n",
    "      \"spring\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Spring.png)\n",
    "        \"variables\": {0: \"spring_constant\", 1: \"weight\", 2: \"defomation\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1],[0,0,1],[0,0,0]])\n",
    "      },\n",
    "      \"Seesaw\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241120_150057.png)\n",
    "        \"variables\": {0: \"seesaw_left_arm\", 1: \"left_weight\", 2: \"seesaw_right_arm\", 3: \"right_weight\", 4: \"seesaw_torque\"},\n",
    "        \"variables_2\": {0: \"left_force\", 1: \"right_force\", 2: \"seesaw_torque\"},\n",
    "        \"adjacency_matrix_2\": np.array([[0,0,1],[0,0,1],[0,0,0]]),\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1],\n",
    "                                        [0, 0, 0, 0, 0]])\n",
    "      },\n",
    "      \"Magnets\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241123_161201_Over_3D_256p.png)\n",
    "        \"variables\": {0: \"neddle_position\", 1: \"magnetic_bar_direction\", 2: \"neddle_direction\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0 , 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/Yellow%20(570-590%20nm)_20241201_100615.png)\n",
    "      \"P_reflection\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"reflected_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/1732947800.585619_rendered_image.png)\n",
    "      \"P_refraction\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"refracted_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      \"3_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"v_cylinder\", 2: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \"4_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "      },\n",
    "      \"5_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\", 4: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"2_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of cylinder\", 1: \"volumn of ball\"},\n",
    "        # b = cos(a) + 5 * epsilon\n",
    "        \"adjacency_matrix\": np.array([[0,1],[0,0]])\n",
    "      },\n",
    "      \"3_V_nonlinear_1\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [1, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "      \"3_V_nonlinear_2\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "    }\n",
    "    \n",
    "  def get_all_scenes(self):\n",
    "    return self.scenes\n",
    "  \n",
    "  def get_scencs_name(self):\n",
    "    return self.scenes.keys()\n",
    "  \n",
    "  def get_scene(self, scene_name):\n",
    "    return self.scenes[scene_name]\n",
    "\n",
    "scene = scene()\n",
    "scene_info_dict = scene.get_scene(\"3_V_nonlinear_2\")\n",
    "h3_nonlinear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h3_nonlinear_1_128P/\"\n",
    "\n",
    "files = os.listdir(h3_nonlinear_img_path)\n",
    "files = [h3_nonlinear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h3_nonlinear_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0)] \n",
      "TPR: 0.1212121212121212\n",
      "[np.float64(0.0), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.16666666666666666)] \n",
      "FPR: 0.045454545454545456\n",
      "[np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(2), np.int64(3), np.int64(3), np.int64(3), np.int64(2), np.int64(4)] \n",
      "SHD: 2.909090909090909\n",
      "[0, np.float64(0.5), np.float64(0.5), 0, 0, np.float64(1.0), 0, 0, 0, np.float64(1.0), np.float64(0.0)] \n",
      "Precision: 0.2727272727272727\n",
      "[np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.3333333333333333), np.float64(0.0)] \n",
      "Recall: 0.1212121212121212\n",
      "[np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.7777777777777778), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.7777777777777778), np.float64(0.5555555555555556)] \n",
      "Accuracy: 0.6767676767676768\n",
      "[0, np.float64(0.4), np.float64(0.4), 0, 0, np.float64(0.5), 0, 0, 0, np.float64(0.5), 0] \n",
      "F1: 0.16363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/133219692.py:110: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h3_nonlinear_2.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0, 0, 1], [1, 0, 1], [0, 0, 0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hpyothetic v_4 nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/google/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[144], line 111\u001b[0m\n    text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h4_nonlinear.csv\")\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[41], line 53\u001b[0m in \u001b[1;35mGemini_infer\u001b[0m\n    matrix = extract_matrix(response.text)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 8\u001b[0;36m in \u001b[0;35mextract_matrix\u001b[0;36m\n\u001b[0;31m    matrix = eval(text[first_index+3:final_index])\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:2\u001b[0;36m\u001b[0m\n\u001b[0;31m    [[0, 0, 0, 0],  // Ball's volume causes nothing\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "import numpy as np\n",
    "\n",
    "class scene:\n",
    "  def __init__(self,):\n",
    "    self.scenes = {\n",
    "      \"reflection\": {\n",
    "        #![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Reflection_circle_320x320.png)\n",
    "        \"variables\": {0: \"incident_degree\", 1: \"reflection_degree\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1], [0, 0]])\n",
    "      },\n",
    "      \"spring\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Spring.png)\n",
    "        \"variables\": {0: \"spring_constant\", 1: \"weight\", 2: \"defomation\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1],[0,0,1],[0,0,0]])\n",
    "      },\n",
    "      \"Seesaw\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241120_150057.png)\n",
    "        \"variables\": {0: \"seesaw_left_arm\", 1: \"left_weight\", 2: \"seesaw_right_arm\", 3: \"right_weight\", 4: \"seesaw_torque\"},\n",
    "        \"variables_2\": {0: \"left_force\", 1: \"right_force\", 2: \"seesaw_torque\"},\n",
    "        \"adjacency_matrix_2\": np.array([[0,0,1],[0,0,1],[0,0,0]]),\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1],\n",
    "                                        [0, 0, 0, 0, 0]])\n",
    "      },\n",
    "      \"Magnets\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241123_161201_Over_3D_256p.png)\n",
    "        \"variables\": {0: \"neddle_position\", 1: \"magnetic_bar_direction\", 2: \"neddle_direction\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0 , 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/Yellow%20(570-590%20nm)_20241201_100615.png)\n",
    "      \"P_reflection\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"reflected_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/1732947800.585619_rendered_image.png)\n",
    "      \"P_refraction\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"refracted_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      \"3_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"v_cylinder\", 2: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \"4_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"distance from ball to cylinder\",\n",
    "                      3: \"cylinder's height above the ground\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1,0],[0,0,1,0],[0,0,0,1],[0,0,0,0]])\n",
    "      },\n",
    "      \"5_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\", 4: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"5_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"height of cylinder\", 2: \"distance between ball and cylinder\", \n",
    "                      3: \"cylinder's height above the ground\", 4: \"tilt angle of cylinder\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1,0,0],[0,0,1,0,0],[0,0,0,0,1],[0,1,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"2_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of cylinder\", 1: \"volumn of ball\"},\n",
    "        # b = cos(a) + 5 * epsilon\n",
    "        \"adjacency_matrix\": np.array([[0,1],[0,0]])\n",
    "      },\n",
    "      \"3_V_nonlinear_1\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [1, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "  def get_all_scenes(self):\n",
    "    return self.scenes\n",
    "  \n",
    "  def get_scencs_name(self):\n",
    "    return self.scenes.keys()\n",
    "  \n",
    "  def get_scene(self, scene_name):\n",
    "    return self.scenes[scene_name]\n",
    "\n",
    "scene = scene()\n",
    "scene_info_dict = scene.get_scene(\"4_V_nonlinear\")\n",
    "h4_nonlinear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h4_128x128_nonlinear/\"\n",
    "\n",
    "files = os.listdir(h4_nonlinear_img_path)\n",
    "files = [h4_nonlinear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h4_nonlinear.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "TPR: 0.0\n",
      "[np.float64(0.07692307692307693), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.07692307692307693), np.float64(0.07692307692307693)] \n",
      "FPR: 0.03619909502262444\n",
      "[np.int64(4), np.int64(3), np.int64(3), np.int64(3), np.int64(4), np.int64(4), np.int64(3), np.int64(4), np.int64(4), np.int64(4), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(4), np.int64(4)] \n",
      "SHD: 3.4705882352941178\n",
      "[np.float64(0.0), 0, 0, 0, np.float64(0.0), np.float64(0.0), 0, np.float64(0.0), np.float64(0.0), np.float64(0.0), 0, 0, 0, 0, 0, np.float64(0.0), np.float64(0.0)] \n",
      "Precision: 0.0\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "Recall: 0.0\n",
      "[np.float64(0.75), np.float64(0.8125), np.float64(0.8125), np.float64(0.8125), np.float64(0.75), np.float64(0.75), np.float64(0.8125), np.float64(0.75), np.float64(0.75), np.float64(0.75), np.float64(0.8125), np.float64(0.8125), np.float64(0.8125), np.float64(0.8125), np.float64(0.8125), np.float64(0.75), np.float64(0.75)] \n",
      "Accuracy: 0.7830882352941176\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/133219692.py:110: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h4_nonlinear_base.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,0,1,0],[0,0,1,0],[0,0,0,1],[0,0,0,0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hpyothetic v_5 nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:02<00:28,  9.50s/it]ERROR:Gemini_infer:Model failed to generate content: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\n",
      " 70%|███████   | 7/10 [01:02<00:26,  9.00s/it]\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.217.1.106:443 {grpc_message:\"Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff.\", grpc_status:8, created_time:\"2025-01-03T02:35:09.568341987-05:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 110\u001b[0m\n\u001b[1;32m     98\u001b[0m   system_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m   setting \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    101\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m : imgs_path,\n\u001b[1;32m    102\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_info\u001b[39m\u001b[38;5;124m\"\u001b[39m : system_info,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \n\u001b[1;32m    108\u001b[0m }\n\u001b[0;32m--> 110\u001b[0m   text, matrix \u001b[38;5;241m=\u001b[39m \u001b[43mGemini_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini_inference_log_h5_nonlinear_base.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 43\u001b[0m, in \u001b[0;36mGemini_infer\u001b[0;34m(setting, csv_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Log the prompt for debugging\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# logger.info(\"Generated Prompt: %s\", prompt)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     45\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel failed to generate content: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:619\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    611\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    612\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/vertexai/generative_models/_generative_models.py:744\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    736\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    737\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    738\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    743\u001b[0m )\n\u001b[0;32m--> 744\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2208\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2208\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/google/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Online prediction request quota exceeded for gemini-1.5-pro. Please try again later with backoff."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "import numpy as np\n",
    "\n",
    "class scene:\n",
    "  def __init__(self,):\n",
    "    self.scenes = {\n",
    "      \"reflection\": {\n",
    "        #![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Reflection_circle_320x320.png)\n",
    "        \"variables\": {0: \"incident_degree\", 1: \"reflection_degree\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1], [0, 0]])\n",
    "      },\n",
    "      \"spring\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Spring.png)\n",
    "        \"variables\": {0: \"spring_constant\", 1: \"weight\", 2: \"defomation\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1],[0,0,1],[0,0,0]])\n",
    "      },\n",
    "      \"Seesaw\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241120_150057.png)\n",
    "        \"variables\": {0: \"seesaw_left_arm\", 1: \"left_weight\", 2: \"seesaw_right_arm\", 3: \"right_weight\", 4: \"seesaw_torque\"},\n",
    "        \"variables_2\": {0: \"left_force\", 1: \"right_force\", 2: \"seesaw_torque\"},\n",
    "        \"adjacency_matrix_2\": np.array([[0,0,1],[0,0,1],[0,0,0]]),\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1],\n",
    "                                        [0, 0, 0, 0, 0]])\n",
    "      },\n",
    "      \"Magnets\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241123_161201_Over_3D_256p.png)\n",
    "        \"variables\": {0: \"neddle_position\", 1: \"magnetic_bar_direction\", 2: \"neddle_direction\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0 , 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/Yellow%20(570-590%20nm)_20241201_100615.png)\n",
    "      \"P_reflection\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"reflected_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/1732947800.585619_rendered_image.png)\n",
    "      \"P_refraction\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"refracted_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      \"3_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"v_cylinder\", 2: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \"4_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "      },\n",
    "      \"5_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\", 4: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"5_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"height of cylinder\", 2: \"distance between ball and cylinder\", \n",
    "                      3: \"cylinder's height above the ground\", 4: \"tilt angle of cylinder\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1,0,0],[0,0,1,0,0],[0,0,0,0,1],[0,1,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"2_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of cylinder\", 1: \"volumn of ball\"},\n",
    "        # b = cos(a) + 5 * epsilon\n",
    "        \"adjacency_matrix\": np.array([[0,1],[0,0]])\n",
    "      },\n",
    "      \"3_V_nonlinear_1\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [1, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "  def get_all_scenes(self):\n",
    "    return self.scenes\n",
    "  \n",
    "  def get_scencs_name(self):\n",
    "    return self.scenes.keys()\n",
    "  \n",
    "  def get_scene(self, scene_name):\n",
    "    return self.scenes[scene_name]\n",
    "\n",
    "scene = scene()\n",
    "scene_info_dict = scene.get_scene(\"5_V_nonlinear\")\n",
    "h5_nonlinear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h5_150x150_nonlinear/\"\n",
    "\n",
    "files = os.listdir(h5_nonlinear_img_path)\n",
    "files = [h5_nonlinear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h5_nonlinear_base.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:56<00:00, 11.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "from utils import info\n",
    "import numpy as np\n",
    "\n",
    "class scene:\n",
    "  def __init__(self,):\n",
    "    self.scenes = {\n",
    "      \"reflection\": {\n",
    "        #![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Reflection_circle_320x320.png)\n",
    "        \"variables\": {0: \"incident_degree\", 1: \"reflection_degree\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1], [0, 0]])\n",
    "      },\n",
    "      \"spring\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/render_output_Blank_Spring.png)\n",
    "        \"variables\": {0: \"spring_constant\", 1: \"weight\", 2: \"defomation\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1],[0,0,1],[0,0,0]])\n",
    "      },\n",
    "      \"Seesaw\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241120_150057.png)\n",
    "        \"variables\": {0: \"seesaw_left_arm\", 1: \"left_weight\", 2: \"seesaw_right_arm\", 3: \"right_weight\", 4: \"seesaw_torque\"},\n",
    "        \"variables_2\": {0: \"left_force\", 1: \"right_force\", 2: \"seesaw_torque\"},\n",
    "        \"adjacency_matrix_2\": np.array([[0,0,1],[0,0,1],[0,0,0]]),\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1],\n",
    "                                        [0, 0, 0, 0, 0]])\n",
    "      },\n",
    "      \"Magnets\": {\n",
    "        # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/20241123_161201_Over_3D_256p.png)\n",
    "        \"variables\": {0: \"neddle_position\", 1: \"magnetic_bar_direction\", 2: \"neddle_direction\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0 , 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/Yellow%20(570-590%20nm)_20241201_100615.png)\n",
    "      \"P_reflection\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"reflected_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      # ![](https://cdn.jsdelivr.net/gh/DishengL/ResearchPics/1732947800.585619_rendered_image.png)\n",
    "      \"P_refraction\": {\n",
    "        \"variables\": {0: \"wave_length\", 1: \"incident_position\", 2: \"incident_angle\", 3: \"refracted_position\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0]])\n",
    "      },\n",
    "      \"3_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"v_cylinder\", 2: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 1, 1], [0, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \"4_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0],[0,0,1,0],[0,0,0,0],[1,0,0,1]])\n",
    "      },\n",
    "      \"5_V\": {\n",
    "        \"variables\": {0: \"v_ball\", 1: \"h_cylinder\", 2: \"d_ball_cylinder\", 3: \"cylinder_h_above\", 4: \"angle\"},\n",
    "        \"adjacency_matrix\": np.array([[0,1,1,0,1],[0,0,1,0,0],[0,0,0,1,1],[0,0,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"5_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"height of cylinder\", 2: \"distance between ball and cylinder\", \n",
    "                      3: \"cylinder's height above the ground\", 4: \"tilt angle of cylinder\"},\n",
    "        \"adjacency_matrix\": np.array([[0,0,1,0,0],[0,0,1,0,0],[0,0,0,0,1],[0,1,0,0,1],[0,0,0,0,0]])\n",
    "      },\n",
    "      \"2_V_nonlinear\": {\n",
    "        \"variables\": {0: \"volumn of cylinder\", 1: \"volumn of ball\"},\n",
    "        # b = cos(a) + 5 * epsilon\n",
    "        \"adjacency_matrix\": np.array([[0,1],[0,0]])\n",
    "      },\n",
    "      \"3_V_nonlinear_1\": {\n",
    "        \"variables\": {0: \"volumn of ball\", 1: \"volumn of cylinder\", 2: \"tile angle of the rectangular prism\"},\n",
    "        \"adjacency_matrix\": np.array([[0, 0, 1], [1, 0, 1], [0, 0, 0]])\n",
    "      },\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "  def get_all_scenes(self):\n",
    "    return self.scenes\n",
    "  \n",
    "  def get_scencs_name(self):\n",
    "    return self.scenes.keys()\n",
    "  \n",
    "  def get_scene(self, scene_name):\n",
    "    return self.scenes[scene_name]\n",
    "\n",
    "scene = scene()\n",
    "scene_info_dict = scene.get_scene(\"5_V_nonlinear\")\n",
    "h5_nonlinear_img_path = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h5_150x150_nonlinear/\"\n",
    "\n",
    "files = os.listdir(h5_nonlinear_img_path)\n",
    "files = [h5_nonlinear_img_path + file for file in files]\n",
    "# randomly pick 10 images\n",
    "for i in tqdm(range(10)):\n",
    "  imgs_path = random.sample(files, 10)\n",
    "  matrix = scene_info_dict['adjacency_matrix']\n",
    "\n",
    "  matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_],')\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  matrix_info = \".\\nIn the matrix, matrix[i][j] = 1 means variable i causes variable j, matrix[i][j] = 0 means there is not direct causal relationship.\"\n",
    "  system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "  \n",
    "  setting = {\n",
    "  \"image_path\" : imgs_path,\n",
    "  \"system_info\" : system_info,\n",
    "  \"scene_info\" : scene_info,\n",
    "  \"matrix\" : matrix,\n",
    "  \"matrix_info\" : matrix_info,\n",
    "  \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "  \n",
    "}\n",
    "\n",
    "  text, matrix = Gemini_infer(setting, csv_file=\"gemini_inference_log_h5_nonlinear.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.4), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2), np.float64(0.0)] \n",
      "TPR: 0.042105263157894736\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.1), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.1), np.float64(0.0), np.float64(0.1), np.float64(0.1), np.float64(0.05), np.float64(0.0), np.float64(0.1), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.05), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.039473684210526314\n",
      "[np.int64(5), np.int64(5), np.int64(7), np.int64(6), np.int64(6), np.int64(4), np.int64(7), np.int64(5), np.int64(7), np.int64(7), np.int64(6), np.int64(4), np.int64(7), np.int64(5), np.int64(5), np.int64(5), np.int64(6), np.int64(4), np.int64(5)] \n",
      "SHD: 5.578947368421052\n",
      "[0, 0, np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.6666666666666666), np.float64(0.0), 0, np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), 0, 0, 0, np.float64(0.0), np.float64(1.0), 0] \n",
      "Precision: 0.14035087719298245\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.4), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.2), np.float64(0.0)] \n",
      "Recall: 0.042105263157894736\n",
      "[np.float64(0.8), np.float64(0.8), np.float64(0.72), np.float64(0.76), np.float64(0.76), np.float64(0.84), np.float64(0.72), np.float64(0.8), np.float64(0.72), np.float64(0.72), np.float64(0.76), np.float64(0.84), np.float64(0.72), np.float64(0.8), np.float64(0.8), np.float64(0.8), np.float64(0.76), np.float64(0.84), np.float64(0.8)] \n",
      "Accuracy: 0.776842105263158\n",
      "[0, 0, 0, 0, 0, np.float64(0.5), 0, 0, 0, 0, 0, np.float64(0.33333333333333337), 0, 0, 0, 0, 0, np.float64(0.33333333333333337), 0] \n",
      "F1: 0.06140350877192983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/133219692.py:110: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h5_nonlinear_base.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,0,1,0,0],[0,0,1,0,0],[0,0,0,0,1],[0,1,0,0,1],[0,0,0,0,0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "[np.float64(0.2), np.float64(0.2), np.float64(0.4), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.2)] \n",
      "TPR: 0.13999999999999999\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.05), np.float64(0.0), np.float64(0.05), np.float64(0.0), np.float64(0.1), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.02\n",
      "[np.int64(4), np.int64(4), np.int64(3), np.int64(6), np.int64(4), np.int64(6), np.int64(4), np.int64(7), np.int64(5), np.int64(4)] \n",
      "SHD: 4.7\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), 0, np.float64(1.0)] \n",
      "Precision: 0.6\n",
      "[np.float64(0.2), np.float64(0.2), np.float64(0.4), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.2), np.float64(0.0), np.float64(0.0), np.float64(0.2)] \n",
      "Recall: 0.13999999999999999\n",
      "[np.float64(0.84), np.float64(0.84), np.float64(0.88), np.float64(0.76), np.float64(0.84), np.float64(0.76), np.float64(0.84), np.float64(0.72), np.float64(0.8), np.float64(0.84)] \n",
      "Accuracy: 0.8119999999999999\n",
      "[np.float64(0.33333333333333337), np.float64(0.33333333333333337), np.float64(0.5714285714285715), 0, np.float64(0.33333333333333337), 0, np.float64(0.33333333333333337), 0, 0, np.float64(0.33333333333333337)] \n",
      "F1: 0.22380952380952385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2563904/133219692.py:110: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_h5_nonlinear.csv\"\n",
    "# csv_file = \"/home/lds/github/Causality-informed-Generation/inference/google_cloud/gemini_inference_log_magnet_basic.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file)\n",
    "(list(df['matrix']))\n",
    "inference = (list(df['matrix']))\n",
    "inference = [eval(i) for i in inference]\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "\n",
    "ground_truth = np.array([[0,0,1,0,0],[0,0,1,0,0],[0,0,0,0,1],[0,1,0,0,1],[0,0,0,0,0]])\n",
    "for matrix in inference:\n",
    "    matrix = np.array(matrix)\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "print(\"explicted\")\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
