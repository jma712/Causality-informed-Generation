{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "\n",
    "from utils import info\n",
    "from utils import evaluation\n",
    "\n",
    "PROJECT_ID = \"mimetic-kit-445917-d8\"\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    raise ValueError(\"Please set your PROJECT_ID\")\n",
    "\n",
    " \n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "from anthropic import AnthropicVertex\n",
    "from google.auth import default, transport\n",
    "import openai\n",
    "from vertexai.evaluation import (\n",
    "    EvalTask,\n",
    "    MetricPromptTemplateExamples,\n",
    "    PairwiseMetric,\n",
    "    PointwiseMetric,\n",
    "    PointwiseMetricPromptTemplate,\n",
    ")\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "import vertexai\n",
    "\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image\n",
    "\n",
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-002\",\n",
    "    generation_config={\n",
    "      \"temperature\": 1, \n",
    "                       \"max_output_tokens\": 500, \"top_k\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matrix(text):\n",
    "  first_index = text.find(\"```\")\n",
    "  final_index = text.rfind(\"```\")\n",
    "  print(text[first_index+3:final_index])\n",
    "  if first_index == -1 or final_index == -1:\n",
    "    raise ValueError(\"Matrix not found in the response\")\n",
    "    return None\n",
    "  matrix = eval(text[first_index+3:final_index])\n",
    "  return matrix\n",
    "\n",
    "\n",
    "def Gemini_infer(setting):\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(\"Gemini_infer\")\n",
    "\n",
    "    # Initialize model with flexible configuration\n",
    "    model = GenerativeModel(\n",
    "        setting.get(\"model_name\", \"default-model-name\"),\n",
    "        generation_config=setting.get(\"generation_config\", {\"temperature\": 0.1, \"max_output_tokens\": 1000, \"top_k\": 1}),\n",
    "    )\n",
    "    csv_file =f\"gemini_inference_log_{setting['scene_name']}_{setting['strategy']}.csv\"\n",
    "    # Load images\n",
    "    imgs = [Part.from_image(Image.load_from_file(path)) for path in setting[\"image_path\"]]\n",
    "    # logger.info(\"Loaded images: %s\", setting[\"image_path\"])\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = imgs + [Part.from_text(\n",
    "        setting[\"system_info\"] +\n",
    "        setting[\"scene_info\"] +\n",
    "        setting[\"matrix\"] +\n",
    "        setting[\"matrix_info\"]\n",
    "    )]\n",
    "    text_prompt = setting[\"system_info\"] + setting[\"scene_info\"] + setting[\"matrix\"] + setting[\"matrix_info\"]\n",
    "    # Log the prompt for debugging\n",
    "    # logger.info(\"Generated Prompt: %s\", prompt)\n",
    "\n",
    "    # Generate response\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Model failed to generate content: %s\", str(e))\n",
    "        raise\n",
    "\n",
    "    # Log the response for debugging\n",
    "    # logger.info(\"Model Response: %s\", response.text)\n",
    "\n",
    "    # Extract matrix\n",
    "    try:\n",
    "        matrix = extract_matrix(response.text)\n",
    "    except ValueError as e:\n",
    "        logger.error(\"Matrix extraction failed: %s\", str(e))\n",
    "        raise\n",
    "\n",
    "    # Log settings, prompt, response, and matrix\n",
    "    # logger.info(\"Settings: %s\", setting)\n",
    "    # logger.info(\"Extracted Matrix: %s\", matrix)\n",
    "\n",
    "    # Get the current timestamp\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    headers = [\"time\", \"strategy\", \"imgs\", \"text_prompt\", \"response\", \"matrix\"]\n",
    "    row = {\n",
    "        \"time\": current_time,\n",
    "        \"strategy\": setting[\"strategy\"],\n",
    "        \"imgs\": str(setting[\"image_path\"]),\n",
    "        \"text_prompt\": str(text_prompt),\n",
    "        \"response\": response.text,\n",
    "        \"matrix\": str(matrix),\n",
    "    }\n",
    "\n",
    "    # Ensure the CSV file is created with headers if it doesn't exist\n",
    "    try:\n",
    "        with open(csv_file, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=headers)\n",
    "            if file.tell() == 0:  # Write headers if the file is empty\n",
    "                writer.writeheader()\n",
    "            writer.writerow(row)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to write to CSV: %s\", str(e))\n",
    "        raise\n",
    "\n",
    "    return response.text, matrix\n",
    "  \n",
    "def compose_content(dict_info):\n",
    "  num_of_v = len(dict_info[\"variables\"])\n",
    "  variables = dict_info[\"variables\"]\n",
    "  content = ''\n",
    "  for i,v in enumerate(variables):\n",
    "    content += f\"{i+1}. {variables[v]}\\n\"\n",
    "  content = f\"There are {num_of_v} variables: \\n{content}.\\n\" \n",
    "  content += \"Please fill this causality adjacency matrix:\\n\"\n",
    "  return content\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def cal_TPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the True Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    TPR = TP / (TP + FN)\n",
    "    \n",
    "    return TPR\n",
    "  \n",
    "def cal_FPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the False Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    TN = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 0))\n",
    "    FPR = FP / (FP + TN)\n",
    "    \n",
    "    return FPR\n",
    "  \n",
    "def cal_SHD_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Structural Hamming Distance between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    SHD = np.sum(ground_truth_matrix1 != matrix2)\n",
    "    \n",
    "    return SHD\n",
    "  \n",
    "def cal_Accuarcy_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Accuarcy between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    Accuarcy = np.sum(ground_truth_matrix1 == matrix2) / ground_truth_matrix1.size\n",
    "    \n",
    "    return Accuarcy\n",
    "  \n",
    "def cal_Precision_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Precision between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    if (TP + FP) == 0:\n",
    "      return 0\n",
    "    Precision = TP / (TP + FP)\n",
    "    \n",
    "    return Precision\n",
    "  \n",
    "def cal_Recall_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Recall between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    Recall = TP / (TP + FN)\n",
    "    \n",
    "    return Recall\n",
    "  \n",
    "def cal_F1_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the F1 between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "\n",
    "    if (TP + FP) == 0:\n",
    "      return 0\n",
    "    Precision = TP / (TP + FP)    \n",
    "\n",
    "    if (TP + FN) == 0:\n",
    "      return 0\n",
    "    Recall = TP / (TP + FN)\n",
    "    F1 = 2 * Precision * Recall / (Precision + Recall)\n",
    "    if (Precision + Recall) == 0:\n",
    "      return 0\n",
    "    \n",
    "    return F1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:12,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:15<01:03,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:23<00:53,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:30<00:45,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:39<00:40,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:47<00:32,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:54<00:22,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:00<00:14,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:08<00:07,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:16<00:00,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0, 0, 0, 0],\n",
      " [0, 0, 0, 0],\n",
      " [0, 0, 0, 1],\n",
      " [0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def inference(image_path = \"/home/lds/github/Causality-informed-Generation/code1/database/Real_magnet_v3/\",\n",
    "              scene_name = \"Magnets\",\n",
    "              strategy = \"basic\"):\n",
    "  magnet_img_path = image_path\n",
    "  scene = info.scene()\n",
    "  scene_info_dict = scene.get_scene(scene_name)\n",
    "  # print(scene_info_dict)\n",
    "\n",
    "  files = os.listdir(magnet_img_path)\n",
    "  files = [magnet_img_path + file for file in files]\n",
    "  scene_info = compose_content(scene_info_dict)\n",
    "  # print(scene_info)\n",
    "  \n",
    "  \n",
    "  matrix_info = \".\\nMatrix[i][j] = 1: Variable i directly causes variable j. Matrix[i][j] = 0: There is no direct causal relationship between variable i and variable j.\"\n",
    "  if strategy == \"explicit\":\n",
    "    system_info = \"You are a causal discovery expert. Your objective is to analyze the provided images and identify any causal relationships between the variables. Use the identified relationships to complete the causality adjacency matrix and provide a brief explanation supporting your conclusions.\"\n",
    "  elif strategy == \"basic\":\n",
    "    system_info = \"Analyze the provided images and identify causal relationships between the variables. Complete the causality adjacency matrix based on the identified relationships and briefly explain your conclusions.\"\n",
    "  for i in tqdm(range(10)):\n",
    "    imgs_path = random.sample(files, 10)\n",
    "    matrix = scene_info_dict['adjacency_matrix']\n",
    "    matrix = str(matrix).replace(\"1\", \"_,\").replace(\"0\", \"_,\").replace(\"_,]\", '_]')\n",
    "    \n",
    "    matrix = (matrix).replace(\"_]\", \"_],\")\n",
    "    \n",
    "    \n",
    "    setting = {\n",
    "    \"image_path\" : imgs_path,\n",
    "    \"system_info\" : system_info,\n",
    "    \"scene_info\" : scene_info,\n",
    "    \"matrix\" : matrix,\n",
    "    \"matrix_info\" : matrix_info,\n",
    "    \"model_name\" : \"gemini-1.5-pro-002\",\n",
    "    \"scene_name\" : scene_name,\n",
    "    \"strategy\" : strategy\n",
    "    \n",
    "  }\n",
    "\n",
    "    text, matrix = Gemini_infer(setting)\n",
    "\n",
    "\n",
    "# \n",
    "stragegies = [\"explicit\"]\n",
    "\n",
    "for strategy in stragegies:\n",
    "  \n",
    "  inference(image_path=\"/home/lds/github/Causality-informed-Generation/code1/database/final_dataset/real/Real_magnet_v3_256P/Real_magnet_v3/\",\n",
    "          strategy=strategy,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
