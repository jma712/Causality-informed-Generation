{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT API inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "api_key=\"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\"\n",
    "\n",
    "# 从环境变量读取 API 密钥\n",
    "openai.api_key =api_key\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"API key not found. Set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# 将图像转换为 base64 格式\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without given varibales\n",
    "<font color=orange>if do not provide the variables within the scene, the gpt's generation is too flexible, which is bad for the following process and metric calculation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_base64_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 调用 GPT-4 Vision API\u001b[39;00m\n\u001b[1;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m  client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo1-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \u001b[38;5;66;03m#\"You are a helpful assistant of causal discovery task among images.\"},\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      7\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m      8\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the causal relationship based on the observation of images? And draw me a causal graph based on the observation of the images.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                Return me a adjancy matrix of the causal graph.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m---> 10\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     11\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     12\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     13\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_3\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     14\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_4\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     15\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_5\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     16\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_6\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     17\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_7\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     18\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_8\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     19\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_9\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     20\u001b[0m         ]}\n\u001b[1;32m     21\u001b[0m     ],\n\u001b[1;32m     22\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 打印返回的结果\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_base64_0' is not defined"
     ]
    }
   ],
   "source": [
    "# 调用 GPT-4 Vision API\n",
    "response =  client.chat.completions.create(\n",
    "    model=\"o1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"}, #\"You are a helpful assistant of causal discovery task among images.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \n",
    "              \"What is the causal relationship based on the observation of images? And draw me a causal graph based on the observation of the images.\\\n",
    "                Return me a adjancy matrix of the causal graph.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_0}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_1}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_2}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_3}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_4}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_5}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_6}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_7}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_8}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_9}\"}},\n",
    "        ]}\n",
    "    ],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# 打印返回的结果\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with given variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_base64_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 调用 GPT-4 Vision API\u001b[39;00m\n\u001b[1;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m  client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m},\u001b[38;5;66;03m#\"You are a helpful assistant of causal discovery task among images.\"},\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      7\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[1;32m      8\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease help me to find the causal relationship among the given varibles(if it exists);\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                1. the incident light direction 2. the reflection direction.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m                  The final return is a causal graph based on the observation of the images represented by a adjancy matrix of the causal graph.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m---> 11\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     12\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     13\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     14\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_3\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     15\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_4\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     16\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_5\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     17\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_6\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     18\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_7\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     19\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_8\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     20\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_base64_9\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}},\n\u001b[1;32m     21\u001b[0m         ]}\n\u001b[1;32m     22\u001b[0m     ],\n\u001b[1;32m     23\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 打印返回的结果\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_base64_0' is not defined"
     ]
    }
   ],
   "source": [
    "# 调用 GPT-4 Vision API\n",
    "response =  client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"},#\"You are a helpful assistant of causal discovery task among images.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \n",
    "              \"Please help me to find the causal relationship among the given varibles(if it exists);\\\n",
    "                1. the incident light direction 2. the reflection direction.\\n\\\n",
    "                  The final return is a causal graph based on the observation of the images represented by a adjancy matrix of the causal graph.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_0}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_1}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_2}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_3}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_4}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_5}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_6}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_7}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_8}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_9}\"}},\n",
    "        ]}\n",
    "    ],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# 打印返回的结果\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "answer = response.choices[0].message.content\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### multi-round conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 GPT-4 Vision API\n",
    "response =  client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant of causal discovery task among images.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \n",
    "              \"Please help me to find the causal relationship among the given varibles(if it exists);\\\n",
    "                1. the incident light direction 2. the reflection direction.\\n\\\n",
    "                  The final return is a causal graph based on the observation of the images represented by a adjancy matrix of the causal graph.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_0}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_1}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_2}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_3}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_4}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_5}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_6}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_7}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_8}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64_9}\"}},\n",
    "        ]},\n",
    "        {\"role\": \"assistant\", \"content\": answer},\n",
    "        {\"role\": \"user\", \"content\": \"Your former answer is not correct. Please try again, and explain why you make that mistake previously.\"},\n",
    "        \n",
    "    ],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# 打印返回的结果\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import random \n",
    "\n",
    "import base64\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "api_key=\"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\"\n",
    "\n",
    "# 从环境变量读取 API 密钥\n",
    "openai.api_key =api_key\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"API key not found. Set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# 将图像转换为 base64 格式\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def get_images(image_dir, img_num):\n",
    "  files = os.listdir(image_dir)\n",
    "  files = [os.path.join(image_dir, f) for f in files]\n",
    "  files = random.sample(files, img_num)\n",
    "  encoded_files = [encode_image(f) for f in files]\n",
    "  return  files,encoded_files\n",
    "  \n",
    "\n",
    "def cal_TPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the True Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if TP + FN == 0:\n",
    "        return 0.0  # No positives in the ground truth, TPR is undefined but logically 0\n",
    "    \n",
    "    # Calculate TPR\n",
    "    TPR = TP / (TP + FN)\n",
    "    return TPR\n",
    "  \n",
    "def cal_FPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the False Positive Rate (FPR) between two adjacency matrices.\n",
    "    Handles cases where FP + TN = 0 to avoid NaN.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth_matrix1 (np.ndarray): Ground truth adjacency matrix.\n",
    "        matrix2 (np.ndarray): Predicted adjacency matrix.\n",
    "    \n",
    "    Returns:\n",
    "        float: The False Positive Rate (FPR), or 0 if no negatives exist in the ground truth.\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "    \n",
    "    # Calculate False Positives (FP) and True Negatives (TN)\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    TN = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 0))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if FP + TN == 0:\n",
    "        return 0.0  # No negatives in the ground truth, FPR is undefined but logically 0\n",
    "    \n",
    "    # Calculate FPR\n",
    "    FPR = FP / (FP + TN)\n",
    "    return FPR\n",
    "  \n",
    "def cal_SHD_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Structural Hamming Distance between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    SHD = np.sum(ground_truth_matrix1 != matrix2)\n",
    "    \n",
    "    return SHD\n",
    "  \n",
    "def cal_Accuarcy_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Accuarcy between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    Accuarcy = np.sum(ground_truth_matrix1 == matrix2) / ground_truth_matrix1.size\n",
    "    \n",
    "    return Accuarcy\n",
    "  \n",
    "def cal_Precision_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Precision between two adjacency matrices.\n",
    "    Precision = TP / (TP + FP)\n",
    "    Returns 0 if (TP + FP) == 0 to avoid division by zero.\n",
    "    \"\"\"\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if TP + FP == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return TP / (TP + FP)\n",
    "  \n",
    "def cal_Recall_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Recall (True Positive Rate) between two adjacency matrices.\n",
    "    Recall = TP / (TP + FN)\n",
    "    Returns 0 if (TP + FN) == 0 to avoid division by zero.\n",
    "    \"\"\"\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if TP + FN == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return TP / (TP + FN)\n",
    "  \n",
    "def cal_F1_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the F1 Score between two adjacency matrices.\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    Returns 0 if (Precision + Recall) == 0 to avoid division by zero.\n",
    "    \"\"\"\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    \n",
    "    # Calculate Precision and Recall\n",
    "    Precision = TP / (TP + FP) if TP + FP > 0 else 0.0\n",
    "    Recall = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if Precision + Recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return 2 * Precision * Recall / (Precision + Recall)\n",
    "  \n",
    "def format_causality_prompt(system_info, scene_info, image_base64_list):\n",
    "    # Format variable list\n",
    "    variables = \"\\n\".join([f\"{i+1}. {var}\" for i, var in enumerate(scene_info[\"variables\"].values())])\n",
    "    \n",
    "    # Format adjacency matrix\n",
    "    adjacency_matrix = \"python```\"+\"[[\" + \"],\\n [\".join(\n",
    "        [\", \".join([\"_\" if val == 0 or  val == 1 else str(val) for val in row]) for row in scene_info['adjacency_matrix']]\n",
    "    ) + \"]]\" + \"```\"\n",
    "\n",
    "    # Construct prompt text\n",
    "    prompt_text = f\"\"\"\n",
    "    Determine the causal relationships within these variables, there are {len(scene_info['variables'])} variables:\n",
    "    {variables}\n",
    "\n",
    "    Please fill this causality adjacency matrix in this format:\n",
    "    {adjacency_matrix}\n",
    "\n",
    "    In the matrix:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_info},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text}\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    text_prompt = system_info + prompt_text\n",
    "    return messages, text_prompt\n",
    "\n",
    "def get_causal_matrix(client, image_base64_list, prompt_type = None, scene_info = None, dump = False):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in seesaw system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt_type == \"explicted\":\n",
    "      system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "    elif prompt_type == \"basic\":\n",
    "      system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "    messages, text_prompt = format_causality_prompt(system_info, scene_info, image_base64_list)\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    # print(response)\n",
    "    if dump:\n",
    "        os.makedirs(\"causal_OpenAI_res\", exist_ok=True)\n",
    "        res = {\n",
    "          \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "          \"prompt_type\": prompt_type,\n",
    "          \"scene_info\": scene_info,\n",
    "          \"message\": text_prompt,\n",
    "          \"response\": response.choices[0].message.content,\n",
    "          \"matrix\": extract_matrix(response.choices[0].message.content)\n",
    "  \n",
    "        }\n",
    "        file_path = \"causal_OpenAI_res/test.csv\"\n",
    "        file_exists = os.path.exists(file_path)\n",
    "        with open(file_path, mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=[\"timestamp\", \"prompt_type\", \"scene_info\", \"message\", \"response\",'matrix'])\n",
    "                \n",
    "                # Write header if the file is new\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                \n",
    "                # Write the data row\n",
    "                writer.writerow(res)\n",
    "    return extract_matrix(response.choices[0].message.content)\n",
    "\n",
    "def extract_matrix(text):\n",
    "  first_index = text.find(\"```python\")\n",
    "  final_index = text.rfind(\"```\")\n",
    "  # print(text[first_index+3:final_index])\n",
    "  if first_index == -1 or final_index == -1:\n",
    "    raise ValueError(\"Matrix not found in the response\")\n",
    "    return None\n",
    "  matrix = eval(text[first_index+9:final_index])\n",
    "  return matrix\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        # print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        matrix = eval(matrix_str)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 5:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 5 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seesaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "api_key=\"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\"\n",
    "\n",
    "# 从环境变量读取 API 密钥\n",
    "openai.api_key =api_key\n",
    "\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"API key not found. Set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# 将图像转换为 base64 格式\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key=\"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=api_key,  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import csv \n",
    "\n",
    "def cal_TPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the True Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    TPR = TP / (TP + FN)\n",
    "    \n",
    "    return TPR\n",
    "  \n",
    "def cal_FPR_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the False Positive Rate between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the True Positive Rate\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    TN = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 0))\n",
    "    FPR = FP / (FP + TN)\n",
    "    \n",
    "    return FPR\n",
    "  \n",
    "def cal_SHD_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Structural Hamming Distance between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    SHD = np.sum(ground_truth_matrix1 != matrix2)\n",
    "    \n",
    "    return SHD\n",
    "  \n",
    "def cal_Accuarcy_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Accuarcy between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    Accuarcy = np.sum(ground_truth_matrix1 == matrix2) / ground_truth_matrix1.size\n",
    "    \n",
    "    return Accuarcy\n",
    "  \n",
    "def cal_Precision_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Precision between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    Precision = TP / (TP + FP)\n",
    "    \n",
    "    return Precision\n",
    "  \n",
    "def cal_Recall_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the Recall between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    Recall = TP / (TP + FN)\n",
    "    \n",
    "    return Recall\n",
    "  \n",
    "def cal_F1_between_matrix(ground_truth_matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Calculate the F1 between two adjacency matrix\n",
    "    \"\"\"\n",
    "    # Check if the matrices are the same size\n",
    "    if ground_truth_matrix1.shape != matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape\")\n",
    "      \n",
    "    # Calculate the Structural Hamming Distance\n",
    "    TP = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 1))\n",
    "    FP = np.sum((ground_truth_matrix1 == 0) & (matrix2 == 1))\n",
    "    FN = np.sum((ground_truth_matrix1 == 1) & (matrix2 == 0))\n",
    "    if TP + FP == 0:\n",
    "        Precision = 0\n",
    "    else:\n",
    "      Precision = TP / (TP + FP)\n",
    "    if TP + FN == 0:\n",
    "        Recall = 0\n",
    "    else:\n",
    "      Recall = TP / (TP + FN)\n",
    "    if Precision + Recall == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "      F1 = 2 * Precision * Recall / (Precision + Recall)\n",
    "    \n",
    "    return F1\n",
    "  \n",
    "def format_causality_prompt(system_info, scene_info, image_base64_list):\n",
    "    # Format variable list\n",
    "    variables = \"\\n\".join([f\"{i+1}. {var}\" for i, var in enumerate(scene_info[\"variables\"].values())])\n",
    "    \n",
    "    # Format adjacency matrix\n",
    "    adjacency_matrix = \"python```\"+\"[[\" + \"],\\n [\".join(\n",
    "        [\", \".join([\"_\" if val == 0 or  val == 1 else str(val) for val in row]) for row in scene_info['adjacency_matrix']]\n",
    "    ) + \"]]\" + \"```\"\n",
    "\n",
    "    # Construct prompt text\n",
    "    prompt_text = f\"\"\"\n",
    "    Determine the causal relationships within these variables, there are {len(scene_info['variables'])} variables:\n",
    "    {variables}\n",
    "\n",
    "    Please fill this causality adjacency matrix in this format:\n",
    "    {adjacency_matrix}\n",
    "\n",
    "    In the matrix:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_info},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text}\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    text_prompt = system_info + prompt_text\n",
    "    return messages, text_prompt\n",
    "\n",
    "\n",
    "def get_causal_matrix(client, image_base64_list, prompt_type = None, scene_info = None, dump = False):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in seesaw system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt_type == \"explicted\":\n",
    "      system_info = \"You are a causal discovery expert. Your task is to analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "    elif prompt_type == \"basic\":\n",
    "      system_info = \"Please analyze the given images and identify any causal relationships present. Provide a brief explanation of the discovered causal relationships to support your conclusions.\"\n",
    "    messages, text_prompt = format_causality_prompt(system_info, scene_info, image_base64_list)\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    # print(response)\n",
    "    if dump:\n",
    "        os.makedirs(\"causal_OpenAI_res\", exist_ok=True)\n",
    "        res = {\n",
    "          \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "          \"prompt_type\": prompt_type,\n",
    "          \"scene_info\": scene_info,\n",
    "          \"message\": text_prompt,\n",
    "          \"response\": response.choices[0].message.content,\n",
    "          \"matrix\": extract_matrix(response.choices[0].message.content)\n",
    "  \n",
    "        }\n",
    "        file_path = \"causal_OpenAI_res/test.csv\"\n",
    "        file_exists = os.path.exists(file_path)\n",
    "        with open(file_path, mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=[\"timestamp\", \"prompt_type\", \"scene_info\", \"message\", \"response\",'matrix'])\n",
    "                \n",
    "                # Write header if the file is new\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                \n",
    "                # Write the data row\n",
    "                writer.writerow(res)\n",
    "    return extract_matrix(response.choices[0].message.content)\n",
    "\n",
    "def extract_matrix(text):\n",
    "  first_index = text.find(\"```python\")\n",
    "  final_index = text.rfind(\"```\")\n",
    "  # print(text[first_index+3:final_index])\n",
    "  if first_index == -1 or final_index == -1:\n",
    "    raise ValueError(\"Matrix not found in the response\")\n",
    "    return None\n",
    "  matrix = eval(text[first_index+9:final_index])\n",
    "  return matrix\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        # print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        matrix = eval(matrix_str)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 5:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 5 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:19<00:00,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.75, 1.0, 0.5, 1.0, 0.5, 0.5, 0.25, 0.75, 1.0, 1.0] \n",
      "TPR: 0.7625\n",
      "[0.0, 0.0, 0.14285714285714285, 0.09523809523809523, 0.0, 0.19047619047619047, 0.09523809523809523, 0.14285714285714285, 0.09523809523809523, 0.09523809523809523, 0.19047619047619047, 0.09523809523809523, 0.14285714285714285, 0.0, 0.19047619047619047, 0.19047619047619047, 0.09523809523809523, 0.047619047619047616, 0.0, 0.0] \n",
      "FPR: 0.09047619047619047\n",
      "[0, 2, 3, 2, 0, 6, 2, 5, 2, 4, 5, 2, 5, 0, 6, 6, 5, 2, 0, 0] \n",
      "SHD: 2.85\n",
      "[1.0, 0.92, 0.88, 0.92, 1.0, 0.76, 0.92, 0.8, 0.92, 0.84, 0.8, 0.92, 0.8, 1.0, 0.76, 0.76, 0.8, 0.92, 1.0, 1.0] \n",
      "Accuracy: 0.8859999999999999\n",
      "[1.0, 1.0, 0.5714285714285714, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.4, 0.6666666666666666, 0.5, 0.42857142857142855, 0.6666666666666666, 0.4, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.75, 1.0, 1.0] \n",
      "Precision: 0.6525000000000001\n",
      "[1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.75, 1.0, 0.5, 1.0, 0.5, 0.5, 0.25, 0.75, 1.0, 1.0] \n",
      "Recall: 0.7625\n",
      "[1.0, 0.6666666666666666, 0.7272727272727273, 0.8, 1.0, 0.4, 0.8, 0.4444444444444445, 0.8, 0.5, 0.5454545454545454, 0.8, 0.4444444444444445, 1.0, 0.4, 0.4, 0.28571428571428575, 0.75, 1.0, 1.0] \n",
      "F1: 0.6881998556998558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_seesaw_128P/\"\n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "    scene_info_dict = scene.get_scene(\"seesaw\")\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            \n",
    "    seesaw_ground_truth = np.array([[0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 0]])\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1s = []\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(seesaw_ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(seesaw_ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(seesaw_ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(seesaw_ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(seesaw_ground_truth, matrix)\n",
    "        recall = cal_Recall_between_matrix(seesaw_ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(seesaw_ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "    print(all_accuracies, '\\nAccuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "    print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "    print(all_f1s, '\\nF1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:32<00:00, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "TPR: 0.85\n",
      "[np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.3333333333333333), np.float64(0.09523809523809523), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.047619047619047616), np.float64(0.0)] \n",
      "FPR: 0.05476190476190477\n",
      "[np.int64(11), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(11), np.int64(2), np.int64(7), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)] \n",
      "SHD: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#basic prompt:\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                        image_base64_3, image_base64_4, image_base64_5,\n",
    "                        image_base64_6, image_base64_7, image_base64_8, \n",
    "                        image_base64_9]\n",
    "    all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type='basic')\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            \n",
    "    seesaw_ground_truth = np.array([[0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 1],\n",
    "                                    [0, 0, 0, 0, 0]])\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    for matrix in all_results:\n",
    "        tpr = cal_TPR_between_matrix(seesaw_ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(seesaw_ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(seesaw_ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "\n",
    "    print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "TPR: 0.85\n",
      "[np.float64(0.3333333333333333), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.3333333333333333), np.float64(0.09523809523809523), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.047619047619047616), np.float64(0.0)] \n",
      "FPR: 0.05476190476190477\n",
      "[np.int64(11), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(3), np.int64(11), np.int64(2), np.int64(7), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)] \n",
      "SHD: 1.75\n",
      "[np.float64(0.56), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.88), np.float64(0.56), np.float64(0.92), np.float64(0.72), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.96), np.float64(1.0)] \n",
      "Accuracy: 0.93\n",
      "[np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5714285714285714), np.float64(0.0), np.float64(0.6666666666666666), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8), np.float64(1.0)] \n",
      "Precision: 0.8019047619047619\n",
      "[np.float64(nan), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.7272727272727273), np.float64(nan), np.float64(0.8), np.float64(nan), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.888888888888889), np.float64(1.0)] \n",
      "F1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1590843/2887683587.py:104: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  F1 = 2 * Precision * Recall / (Precision + Recall)\n"
     ]
    }
   ],
   "source": [
    "seesaw_ground_truth = np.array([[0, 0, 0, 0, 1],\n",
    "                                [0, 0, 0, 0, 1],\n",
    "                                [0, 0, 0, 0, 1],\n",
    "                                [0, 0, 0, 0, 1],\n",
    "                                [0, 0, 0, 0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_F1s = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(seesaw_ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(seesaw_ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(seesaw_ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(seesaw_ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(seesaw_ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(seesaw_ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "    all_F1s.append(F1)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_accuracies, '\\nAccuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## spring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_0 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_002033.png\"\n",
    "image_path_1 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_002040.png\"\n",
    "image_path_2 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005031.png\"\n",
    "image_path_3 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005046.png\"\n",
    "image_path_4 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005135.png\"\n",
    "image_path_5 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005631.png\"\n",
    "image_path_6 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005237.png\"\n",
    "image_path_7 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005238.png\"\n",
    "image_path_8 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005123.png\"\n",
    "image_path_9 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_spring_128P/20241216_005036.png\"\n",
    "\n",
    "\n",
    "# 编码图像\n",
    "image_base64_0 = encode_image(image_path_0)\n",
    "image_base64_1 = encode_image(image_path_1)\n",
    "image_base64_2 = encode_image(image_path_2)\n",
    "image_base64_3 = encode_image(image_path_3)\n",
    "image_base64_4 = encode_image(image_path_4)\n",
    "image_base64_5 = encode_image(image_path_5)\n",
    "image_base64_6 = encode_image(image_path_6)\n",
    "image_base64_7 = encode_image(image_path_7)\n",
    "image_base64_8 = encode_image(image_path_8)\n",
    "image_base64_9 = encode_image(image_path_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_matrix(client, image_base64_list, prompt = None):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in spring system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt == 'explicted':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a highly knowledgeable AI system tasked with analyzing causal relationships between variables. Analyze the images and return a 3x3 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between these spring system variables: \n",
    "                    \n",
    "                    1. spring constant\n",
    "                    2. weight mass\n",
    "                    3. defomation\n",
    "\n",
    "    Return  a 3x3 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,0,],\n",
    "    [1,0,0],\n",
    "    [1,0,0,]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    elif prompt == 'basic':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Analyze the images and return a 3x3 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between these spring system variables: \n",
    "                    \n",
    "                    1. spring constant\n",
    "                    2. weight mass\n",
    "                    3. defomation\n",
    "\n",
    "    Return  a 3x3 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,0,],\n",
    "    [1,0,0],\n",
    "    [1,0,0,]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "    else:\n",
    "      raise ValueError(\"Invalid prompt type\")\n",
    "        \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    # print(response)\n",
    "    return parse_matrix_response(response.choices[0].message.content)\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        # print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        # print(matrix_str)\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        # print(matrix_str)\n",
    "        \n",
    "        matrix = eval(matrix_str)\n",
    "        # print(matrix)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 3:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 3 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:11<01:46, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Matrix parsing failed: invalid syntax (<string>, line 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:59<00:00, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0)] \n",
      "TPR: 0.9444444444444444\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.14285714285714285), np.float64(0.0), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.0)] \n",
      "FPR: 0.047619047619047616\n",
      "[np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(3), np.int64(0)] \n",
      "SHD: 0.4444444444444444\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8), np.float64(1.0), np.float64(1.0), np.float64(0.4), np.float64(1.0)] \n",
      "F1: 0.911111111111111\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.8888888888888888), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(1.0)] \n",
      "Accuracy: 0.9506172839506175\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.3333333333333333), np.float64(1.0)] \n",
      "Precision: 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='explicted')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array([[0, 0, 1],\n",
    "                                [0, 0, 1],\n",
    "                                [0, 0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_F1s = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "    all_F1s.append(F1)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))\n",
    "print(all_accuracies, '\\nAccuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:48<00:00, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(1.0), np.float64(0.5), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "TPR: 0.95\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(0.2857142857142857), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)] \n",
      "FPR: 0.02857142857142857\n",
      "[np.int64(0), np.int64(0), np.int64(3), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)] \n",
      "SHD: 0.3\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(0.4), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "F1: 0.9400000000000001\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Accuracy: 0.9666666666666666\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(0.3333333333333333), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Precision: 0.9333333333333333\n",
      "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(0.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)] \n",
      "Recall: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='basic')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array([[0, 0, 1],\n",
    "                                [0, 0, 1],\n",
    "                                [0, 0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_F1s = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "    all_F1s.append(F1)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))\n",
    "print(all_accuracies, '\\nAccuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    "## magnetic field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_0 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_000324_Over_3D_128p.png\"\n",
    "image_path_1 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_000409_Over_3D_128p.png\"\n",
    "image_path_2 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_000456_Over_3D_128p.png\"\n",
    "image_path_3 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_000613_Over_3D_128p.png\"\n",
    "image_path_4 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_000806_Over_3D_128p.png\"\n",
    "image_path_5 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_000945_Over_3D_128p.png\"\n",
    "image_path_6 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_001320_Over_3D_128p.png\"\n",
    "image_path_7 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_001408_Over_3D_128p.png\"\n",
    "image_path_8 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_001423_Over_3D_128p.png\"\n",
    "image_path_9 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_magnetic_128P/20241216_001954_Over_3D_128p.png\"\n",
    "\n",
    "\n",
    "# 编码图像\n",
    "image_base64_0 = encode_image(image_path_0)\n",
    "image_base64_1 = encode_image(image_path_1)\n",
    "image_base64_2 = encode_image(image_path_2)\n",
    "image_base64_3 = encode_image(image_path_3)\n",
    "image_base64_4 = encode_image(image_path_4)\n",
    "image_base64_5 = encode_image(image_path_5)\n",
    "image_base64_6 = encode_image(image_path_6)\n",
    "image_base64_7 = encode_image(image_path_7)\n",
    "image_base64_8 = encode_image(image_path_8)\n",
    "image_base64_9 = encode_image(image_path_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_matrix(client, image_base64_list, prompt = None):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in spring system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt == 'explicted':\n",
    "       messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a highly knowledgeable AI system tasked with analyzing causal relationships between variables. Analyze the images and return a 3x3 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following magnetic field system variables, based on the provided images: \n",
    "                    1. Location of the needle (x)\n",
    "                    2. Location of the needle (y)\n",
    "                    3. Direction of the magnetic bar\n",
    "                    4. Direction of the needle\n",
    "                    \n",
    "    Return  a 3x3 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[_,_,_,_],\n",
    "    [_,_,_,_],\n",
    "    [_,_,_,_],\n",
    "    [_,_,_,_],]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    elif prompt == 'basic':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Analyze the images and return a 3x3 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following magnetic field system variables, based on the provided images: \n",
    "                    1. Location of the needle (x)\n",
    "                    2. Location of the needle (y)\n",
    "                    3. Direction of the magnetic bar\n",
    "                    4. Direction of the needle\n",
    "\n",
    "    Return  a 4x4 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    ```\n",
    "    [\n",
    "      [_,_,_,_],\n",
    "      [_,_,_,_],\n",
    "      [_,_,_,_],\n",
    "      [_,_,_,_]\n",
    "      ]\n",
    "    ```\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    print(response)\n",
    "    return parse_matrix_response(response.choices[0].message.content)\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        # print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        # print(matrix_str)\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        # print(matrix_str)\n",
    "        \n",
    "        matrix = eval(matrix_str)\n",
    "        # print(matrix)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 3:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 3 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:14<02:10, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Ask39iobk60ApLG9CWlSburwWBEuJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"To determine the causal relationships between the specified variables in the magnetic field system, we analyze how changes in one variable may influence the others based on the interactions typically observed in such systems.\\n\\n### Variable List:\\n1. Location of the needle (x)\\n2. Location of the needle (y)\\n3. Direction of the magnetic bar\\n4. Direction of the needle\\n\\n### Analysis:\\n1. **Location of the needle (x)** and **Location of the needle (y)**: The location of the needle in one direction may influence its location in another, but they don't directly cause each other.\\n  \\n2. **Direction of the magnetic bar**: This variable can influence the direction of the needle, as the magnetic field produced by the bar will affect how the needle aligns itself.\\n\\n3. **Direction of the needle**: The location of the needle in the x or y direction does not typically influence the direction itself but is rather the result of the magnetic forces.\\n\\n### Causal Relationships:\\n- **Location of the needle (x)** does not directly cause the others.\\n- **Location of the needle (y)** does not directly cause the others.\\n- **Direction of the magnetic bar** can directly cause the **Direction of the needle**.\\n- **Direction of the needle** does not influence the others.\\n\\n### Adjacency Matrix\\nBased on the above analysis, the adjacency matrix will be:\\n```python\\nadjacency_matrix = [\\n    [0, 0, 0, 0],  # Location of the needle (x)\\n    [0, 0, 0, 0],  # Location of the needle (y)\\n    [0, 0, 0, 1],  # Direction of the magnetic bar\\n    [0, 0, 0, 0],  # Direction of the needle\\n]\\n```\\n\\nHere's the final output in the expected format:\\n\\n```python\\nadjacency_matrix = [\\n    [0, 0, 0, 0],\\n    [0, 0, 0, 0],\\n    [0, 0, 0, 1],\\n    [0, 0, 0, 0],\\n]\\n```\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737610091, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=448, prompt_tokens=2551, total_tokens=2999, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2432)))\n",
      "Error: Matrix parsing failed: Invalid matrix dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:23<01:28, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Ask3NAdxC5aq6KYwnCNxFJF34VhPy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Based on the provided magnetic field system variables and their potential causal relationships, we can deduce the following:\\n\\n1. The location of the needle in the x-direction (x) can influence the direction that the needle points (direction of the needle). \\n2. The location of the needle in the y-direction (y) also impacts the direction of the needle.\\n3. The direction of the magnetic bar will influence the direction of the needle but will not directly impact its location.\\n\\nSo, the adjacency matrix based on these relationships can be structured as follows:\\n\\n```python\\nadjacency_matrix = [\\n    [0, 0, 0, 1],  # x -> direction of needle\\n    [0, 0, 0, 1],  # y -> direction of needle\\n    [0, 0, 0, 1],  # direction of magnetic bar -> direction of needle\\n    [0, 0, 0, 0],  # direction of needle does not directly cause any other variable\\n]\\n```\\n\\nThus, the final adjacency matrix is:\\n\\n```python\\nadjacency_matrix = [\\n    [0, 0, 0, 1],\\n    [0, 0, 0, 1],\\n    [0, 0, 0, 1],\\n    [0, 0, 0, 0],\\n]\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737610105, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=284, prompt_tokens=2551, total_tokens=2835, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2432)))\n",
      "Error: Matrix parsing failed: Invalid matrix dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:23<01:35, 11.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m         matrix \u001b[38;5;241m=\u001b[39m \u001b[43mget_causal_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_base64_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexplicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# print(\"Causal Adjacency Matrix:\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(matrix)\n",
      "Cell \u001b[0;32mIn[20], line 78\u001b[0m, in \u001b[0;36mget_causal_matrix\u001b[0;34m(client, image_base64_list, prompt)\u001b[0m\n\u001b[1;32m     41\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyze the images and return a 3x3 adjacency matrix as a Python list of lists.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     43\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m         ]\n\u001b[1;32m     75\u001b[0m     }]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Make the API call\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Parse the response\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/openai/resources/chat/completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/openai/_base_client.py:996\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    993\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 996\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1002\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/ssl.py:1260\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1259\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/joe/lib/python3.9/ssl.py:1135\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='explicted')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array([[0, 0, 0, 1,],\n",
    "                                [0, 0, 0, 1,],\n",
    "                                [0, 0, 0, 1,],\n",
    "                                [0, 0, 0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_F1s = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "    all_F1s.append(F1)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))\n",
    "print(all_accuracies, '\\nAccuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_base64_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)  \u001b[38;5;66;03m# this is also the default, it can be omitted)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image_base64_list \u001b[38;5;241m=\u001b[39m [\u001b[43mimage_base64_0\u001b[49m, image_base64_1, image_base64_2, \n\u001b[1;32m      3\u001b[0m                     image_base64_3, image_base64_4, image_base64_5,\n\u001b[1;32m      4\u001b[0m                     image_base64_6, image_base64_7, image_base64_8, \n\u001b[1;32m      5\u001b[0m                     image_base64_9]\n\u001b[1;32m      6\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_base64_0' is not defined"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='basic')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array([[0, 0, 1],\n",
    "                                [0, 0, 1],\n",
    "                                [0, 0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_F1s = []\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "    all_F1s.append(F1)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))\n",
    "print(all_accuracies, '\\nAccuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path_0 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021540.png\"\n",
    "image_path_1 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241216_132643.png\"\n",
    "image_path_2 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021653.png\"\n",
    "image_path_3 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021614.png\"\n",
    "image_path_4 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021545.png\"\n",
    "image_path_5 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021623.png\"\n",
    "image_path_6 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021742.png\"\n",
    "image_path_7 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021733.png\"\n",
    "image_path_8 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021823.png\"\n",
    "image_path_9 = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_reflection_128P/20241217_021841.png\"\n",
    "\n",
    "\n",
    "# 编码图像\n",
    "image_base64_0 = encode_image(image_path_0)\n",
    "image_base64_1 = encode_image(image_path_1)\n",
    "image_base64_2 = encode_image(image_path_2)\n",
    "image_base64_3 = encode_image(image_path_3)\n",
    "image_base64_4 = encode_image(image_path_4)\n",
    "image_base64_5 = encode_image(image_path_5)\n",
    "image_base64_6 = encode_image(image_path_6)\n",
    "image_base64_7 = encode_image(image_path_7)\n",
    "image_base64_8 = encode_image(image_path_8)\n",
    "image_base64_9 = encode_image(image_path_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_matrix(client, image_base64_list, prompt = None):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in spring system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt == 'explicted':\n",
    "       messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a highly knowledgeable AI system tasked with analyzing causal relationships between variables. Analyze the images and return a 2x2 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following optical variables, based on the provided images: \n",
    "                    1. Incident degree\n",
    "                    2. Reflection degree\n",
    "\n",
    "\n",
    "    Return  a 2x2 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,],\n",
    "    [1,0]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    elif prompt == 'basic':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Analyze the images and return a 2x2 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following optical variables, based on the provided images: \n",
    "                    1. Incident degree\n",
    "                    2. Reflection degree\n",
    "\n",
    "    Return  a 2x2 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1],\n",
    "    [1,0]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    # print(response)\n",
    "    return parse_matrix_response(response.choices[0].message.content)\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        print(matrix_str)\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        print(matrix_str)\n",
    "        \n",
    "        matrix = eval(matrix_str)\n",
    "        print(matrix)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 2:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 2 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='explicted')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array([[0, 1],\n",
    "                         [0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='basic')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array([[0, 1],\n",
    "                         [0, 0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    all_shds.append(shd)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Refraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path_0 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Yellow (570-590 nm)_20241204_004043.png\"\n",
    "image_path_1 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Yellow (570-590 nm)_20241202_182014.png\"\n",
    "image_path_2 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Violet (380-450 nm)_20241202_180004.png\"\n",
    "image_path_3 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Red (620-750 nm)_20241202_175336.png\"\n",
    "image_path_4 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Red (620-750 nm)_20241201_101806.png\"\n",
    "image_path_5 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Orange (590-620 nm)_20241202_174534.png\"\n",
    "image_path_6 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Orange (590-620 nm)_20241202_161355.png\"\n",
    "image_path_7 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Orange (590-620 nm)_20241201_135253.png\"\n",
    "image_path_8 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Green (495-570 nm)_20241204_003717.png\"\n",
    "image_path_9 = \"/home/lds/github/Causality-informed-Generation/code1/database/prism_reflection/Green (495-570 nm)_20241204_000050.png\"\n",
    "\n",
    "# the colors  of light are ['yellow', 'yellow', 'violet', 'red', 'red', 'orange', 'orange', 'orange', 'green', 'green']\n",
    "# 编码图像\n",
    "image_base64_0 = encode_image(image_path_0)\n",
    "image_base64_1 = encode_image(image_path_1)\n",
    "image_base64_2 = encode_image(image_path_2)\n",
    "image_base64_3 = encode_image(image_path_3)\n",
    "image_base64_4 = encode_image(image_path_4)\n",
    "image_base64_5 = encode_image(image_path_5)\n",
    "image_base64_6 = encode_image(image_path_6)\n",
    "image_base64_7 = encode_image(image_path_7)\n",
    "image_base64_8 = encode_image(image_path_8)\n",
    "image_base64_9 = encode_image(image_path_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_matrix(client, image_base64_list, prompt = None):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in spring system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt == 'explicted':\n",
    "       messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a highly knowledgeable AI system tasked with analyzing causal relationships between variables. Analyze the images and return a 4x4 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following optical variables, based on the provided images, and the colors  of light within it are 'yellow', 'yellow', 'violet', 'red', 'red', 'orange', 'orange', 'orange', 'green', 'green' respectively: \n",
    "                    1. Wave Length\n",
    "                    2. Incident Position\n",
    "                    3. Incident Angle\n",
    "                    4. Reflected Position\n",
    "                  \n",
    "\n",
    "\n",
    "    Return  a 4x4 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,0,1],\n",
    "    [1,0,1,0],\n",
    "    [1,0,0,0],\n",
    "    [0,0,0,0]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    elif prompt == 'basic':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Analyze the images and return a 2x2 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following optical variables, based on the provided images, and the colors  of light within it are 'yellow', 'yellow', 'violet', 'red', 'red', 'orange', 'orange', 'orange', 'green', 'green' respectively: \n",
    "                    1. Wave Length\n",
    "                    2. Incident Position\n",
    "                    3. Incident Angle\n",
    "                    4. Reflected Position\n",
    "\n",
    "    Return  a 2x2 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,0,1],\n",
    "    [1,0,1,0],\n",
    "    [1,0,0,0],\n",
    "    [0,0,0,0]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    # print(response)\n",
    "    return parse_matrix_response(response.choices[0].message.content)\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        print(matrix_str)\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        print(matrix_str)\n",
    "        \n",
    "        matrix = eval(matrix_str)\n",
    "        print(matrix)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 4:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 4 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='explicted')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.6666666666666666)] \n",
      "TPR: 0.6282051282051282\n",
      "[np.float64(0.15384615384615385), np.float64(0.3076923076923077), np.float64(0.23076923076923078), np.float64(0.15384615384615385), np.float64(0.07692307692307693), np.float64(0.15384615384615385), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.23076923076923078), np.float64(0.15384615384615385), np.float64(0.23076923076923078), np.float64(0.07692307692307693), np.float64(0.15384615384615385), np.float64(0.23076923076923078), np.float64(0.15384615384615385), np.float64(0.07692307692307693), np.float64(0.15384615384615385), np.float64(0.3076923076923077), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.38461538461538464), np.float64(0.15384615384615385), np.float64(0.23076923076923078), np.float64(0.3076923076923077), np.float64(0.23076923076923078)] \n",
      "FPR: 0.21005917159763318\n",
      "[np.int64(3), np.int64(6), np.int64(4), np.int64(4), np.int64(2), np.int64(3), np.int64(6), np.int64(5), np.int64(3), np.int64(4), np.int64(5), np.int64(1), np.int64(4), np.int64(3), np.int64(4), np.int64(1), np.int64(3), np.int64(6), np.int64(4), np.int64(3), np.int64(3), np.int64(6), np.int64(3), np.int64(5), np.int64(5), np.int64(4)] \n",
      "SHD: 3.8461538461538463\n",
      "[np.float64(0.5), np.float64(0.2), np.float64(0.4), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.5), np.float64(0.2), np.float64(0.3333333333333333), np.float64(0.5), np.float64(0.3333333333333333), np.float64(0.25), np.float64(0.75), np.float64(0.3333333333333333), np.float64(0.5), np.float64(0.3333333333333333), np.float64(0.75), np.float64(0.5), np.float64(0.2), np.float64(0.4), np.float64(0.5), np.float64(0.5), np.float64(0.2857142857142857), np.float64(0.5), np.float64(0.25), np.float64(0.3333333333333333), np.float64(0.4)] \n",
      "Precision: 0.41355311355311364\n",
      "[np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.3333333333333333), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(1.0), np.float64(1.0), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.6666666666666666)] \n",
      "Recall: 0.6282051282051282\n",
      "[np.float64(0.8125), np.float64(0.625), np.float64(0.75), np.float64(0.75), np.float64(0.875), np.float64(0.8125), np.float64(0.625), np.float64(0.6875), np.float64(0.8125), np.float64(0.75), np.float64(0.6875), np.float64(0.9375), np.float64(0.75), np.float64(0.8125), np.float64(0.75), np.float64(0.9375), np.float64(0.8125), np.float64(0.625), np.float64(0.75), np.float64(0.8125), np.float64(0.8125), np.float64(0.625), np.float64(0.8125), np.float64(0.6875), np.float64(0.6875), np.float64(0.75)] \n",
      "Accuracy: 0.7596153846153846\n",
      "[np.float64(0.5714285714285715), np.float64(0.25), np.float64(0.5), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.5714285714285715), np.float64(0.25), np.float64(0.4444444444444444), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.28571428571428575), np.float64(0.8571428571428571), np.float64(0.3333333333333333), np.float64(0.6666666666666666), np.float64(0.3333333333333333), np.float64(0.8571428571428571), np.float64(0.5714285714285715), np.float64(0.25), np.float64(0.5), np.float64(0.6666666666666666), np.float64(0.6666666666666666), np.float64(0.4), np.float64(0.5714285714285715), np.float64(0.28571428571428575), np.float64(0.4444444444444444), np.float64(0.5)] \n",
      "F1: 0.4914224664224664\n"
     ]
    }
   ],
   "source": [
    "ground_truth = np.array(    \n",
    "                        [[0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='basic')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array(    \n",
    "                        [[0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Prism transimission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_0 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Blue (450-495 nm)_20241201_093744.png\"\n",
    "image_path_1 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Blue (450-495 nm)_20241201_094018.png\"\n",
    "image_path_2 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Orange (590-620 nm)_20241202_201126.png\"\n",
    "image_path_3 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Orange (590-620 nm)_20241202_201201.png\"\n",
    "image_path_4 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Red (620-750 nm)_20241201_110934.png\"\n",
    "image_path_5 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Red (620-750 nm)_20241201_111802.png\"\n",
    "image_path_6 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Violet (380-450 nm)_20241202_192847.png\"\n",
    "image_path_7 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Violet (380-450 nm)_20241202_192815.png\"\n",
    "image_path_8 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Yellow (570-590 nm)_20241201_102721.png\"\n",
    "image_path_9 = \"/home/lds/github/Causality-informed-Generation/code1/database/transmission/Yellow (570-590 nm)_20241201_103404.png\"\n",
    "\n",
    "# the colors  of light are [''blue', 'blue', 'orange', 'orange', 'red', 'red', 'violet', 'violet', 'yellow', 'yellow']\n",
    "# 编码图像\n",
    "image_base64_0 = encode_image(image_path_0)\n",
    "image_base64_1 = encode_image(image_path_1)\n",
    "image_base64_2 = encode_image(image_path_2)\n",
    "image_base64_3 = encode_image(image_path_3)\n",
    "image_base64_4 = encode_image(image_path_4)\n",
    "image_base64_5 = encode_image(image_path_5)\n",
    "image_base64_6 = encode_image(image_path_6)\n",
    "image_base64_7 = encode_image(image_path_7)\n",
    "image_base64_8 = encode_image(image_path_8)\n",
    "image_base64_9 = encode_image(image_path_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_matrix(client, image_base64_list, prompt = None):\n",
    "    \"\"\"\n",
    "    Makes an API call to determine causal relationships in spring system images\n",
    "    Returns a parsed adjacency matrix\n",
    "    \"\"\"\n",
    "    # Construct the messages list with optimized prompt\n",
    "    if prompt == 'explicted':\n",
    "       messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a highly knowledgeable AI system tasked with analyzing causal relationships between variables. Analyze the images and return a 4x4 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following optical variables, based on the provided images, and the colors  of light within it are 'blue', 'blue', 'orange', 'orange', 'red', 'red', 'violet', 'violet', 'yellow', 'yellow' respectively: \n",
    "                    1. Wave Length\n",
    "                    2. Incident Position\n",
    "                    3. Incident Angle\n",
    "                    4. Refracted Position\n",
    "                  \n",
    "\n",
    "\n",
    "    Return  a 4x4 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,0,1],\n",
    "    [1,0,1,0],\n",
    "    [1,0,0,0],\n",
    "    [0,0,0,0]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "                }\n",
    "            ] + [\n",
    "                {\"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    elif prompt == 'basic':\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Analyze the images and return a 2x2 adjacency matrix as a Python list of lists.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Determine the causal relationships between the following optical variables, based on the provided images, and the colors  of light within it are 'blue', 'blue', 'orange', 'orange', 'red', 'red', 'violet', 'violet', 'yellow', 'yellow' respectively: \n",
    "                    1. Wave Length\n",
    "                    2. Incident Position\n",
    "                    3. Incident Angle\n",
    "                    4. Refracted Position\n",
    "\n",
    "    Return  a 2x2 adjacency matrix as a Python list of lists where:\n",
    "    - Matrix[i][j] = 1 if variable i directly causes variable j\n",
    "    - Matrix[i][j] = 0 if no direct causal relationship\n",
    "    - Use the exact variable order listed above\n",
    "\n",
    "    Expected format:\n",
    "    [[0,1,0,1],\n",
    "    [1,0,1,0],\n",
    "    [1,0,0,0],\n",
    "    [0,0,0,0]]\n",
    "    \n",
    "    So, the adjacency_matrix = \n",
    "    \"\"\"\n",
    "              }\n",
    "            ] + \n",
    "             [\n",
    "                {\n",
    "                  \"type\": \"image_url\", \n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}\n",
    "                }\n",
    "                for img_base64 in image_base64_list\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o1-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    # print(response)\n",
    "    return parse_matrix_response(response.choices[0].message.content)\n",
    "\n",
    "def parse_matrix_response(response_text):\n",
    "    \"\"\"\n",
    "    Extracts and validates the adjacency matrix from API response\n",
    "    Returns numpy array for easier manipulation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the matrix pattern\n",
    "        start_idx = response_text.find('adjacency_matrix = ')\n",
    "        end_idx = response_text.find(']\\n') + 2\n",
    "        print(start_idx, end_idx)\n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            raise ValueError(\"Matrix not found in response\")\n",
    "            \n",
    "        matrix_str = response_text[start_idx:end_idx]\n",
    "        print(matrix_str)\n",
    "        # Convert to Python list and validate\n",
    "        matrix_str = matrix_str.replace('adjacency_matrix = ', '')\n",
    "        print(matrix_str)\n",
    "        \n",
    "        matrix = eval(matrix_str)\n",
    "        print(matrix)\n",
    "        \n",
    "        # Validation checks\n",
    "        if not isinstance(matrix, list) or len(matrix) != 4:\n",
    "            raise ValueError(\"Invalid matrix dimensions\")\n",
    "            \n",
    "        if not all(len(row) == 4 for row in matrix):\n",
    "            raise ValueError(\"Inconsistent row lengths\")\n",
    "            \n",
    "        if not all(all(x in {0, 1} for x in row) for row in matrix):\n",
    "            raise ValueError(\"Invalid entries: must be 0 or 1\")\n",
    "            \n",
    "        return np.array(matrix)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Matrix parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_base64_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)  \u001b[38;5;66;03m# this is also the default, it can be omitted)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_base64_list \u001b[38;5;241m=\u001b[39m [\u001b[43mimage_base64_0\u001b[49m, image_base64_1, image_base64_2, \n\u001b[1;32m      5\u001b[0m                     image_base64_3, image_base64_4, image_base64_5,\n\u001b[1;32m      6\u001b[0m                     image_base64_6, image_base64_7, image_base64_8, \n\u001b[1;32m      7\u001b[0m                     image_base64_9]\n\u001b[1;32m      8\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_base64_0' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='explicted')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array(    \n",
    "                        [[0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_base64_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)  \u001b[38;5;66;03m# this is also the default, it can be omitted)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_base64_list \u001b[38;5;241m=\u001b[39m [\u001b[43mimage_base64_0\u001b[49m, image_base64_1, image_base64_2, \n\u001b[1;32m      5\u001b[0m                     image_base64_3, image_base64_4, image_base64_5,\n\u001b[1;32m      6\u001b[0m                     image_base64_6, image_base64_7, image_base64_8, \n\u001b[1;32m      7\u001b[0m                     image_base64_9]\n\u001b[1;32m      8\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_base64_0' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "image_base64_list = [image_base64_0, image_base64_1, image_base64_2, \n",
    "                    image_base64_3, image_base64_4, image_base64_5,\n",
    "                    image_base64_6, image_base64_7, image_base64_8, \n",
    "                    image_base64_9]\n",
    "all_results = []\n",
    "for i in tqdm(range(30)):\n",
    "    try:\n",
    "        matrix = get_causal_matrix(client, image_base64_list, prompt='basic')\n",
    "        # print(\"Causal Adjacency Matrix:\")\n",
    "        # print(matrix)\n",
    "        all_results.append(matrix)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        \n",
    "ground_truth = np.array(    \n",
    "                        [[0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,1],\n",
    "                         [0,0,0,0]])\n",
    "\n",
    "all_tprs = []\n",
    "all_fprs = []\n",
    "all_shds = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_accuracys = []\n",
    "all_F1s = []\n",
    "for matrix in all_results:\n",
    "    tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "    fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "    shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "    precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "    recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "    accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "    F1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "    \n",
    "    all_tprs.append(tpr)\n",
    "    all_fprs.append(fpr)\n",
    "    \n",
    "    all_shds.append(shd)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_accuracys.append(accuracy)\n",
    "    all_F1s.append(F1)\n",
    "\n",
    "print(all_tprs, '\\nTPR:', sum(all_tprs)/len(all_tprs))\n",
    "print(all_fprs, '\\nFPR:', sum(all_fprs)/len(all_fprs))\n",
    "print(all_shds, '\\nSHD:', sum(all_shds)/len(all_shds))\n",
    "print(all_precisions, '\\nPrecision:', sum(all_precisions)/len(all_precisions))\n",
    "print(all_recalls, '\\nRecall:', sum(all_recalls)/len(all_recalls))\n",
    "print(all_accuracys, '\\nAccuracy:', sum(all_accuracys)/len(all_accuracys))\n",
    "print(all_F1s, '\\nF1:', sum(all_F1s)/len(all_F1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 169809.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     all_precisions\u001b[38;5;241m.\u001b[39mappend(precision)\n\u001b[1;32m     58\u001b[0m     all_f1s\u001b[38;5;241m.\u001b[39mappend(f1)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPR:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_tprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_tprs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPR:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28msum\u001b[39m(all_fprs)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_fprs))\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHD:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28msum\u001b[39m(all_shds)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_shds))\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h3_128P/\"\n",
    "    scene_info_dict = scene.get_scene(\"3_V\")\n",
    "    \n",
    "    \n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_f1s = []\n",
    "\n",
    "    basic_all_tprs = []\n",
    "    basic_all_fprs = []\n",
    "    basic_all_shds = []\n",
    "    basic_all_precisions = []\n",
    "    basic_all_accuracies = []\n",
    "    \n",
    "    basic_all_F1s = []      \n",
    "\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    ground_truth = scene_info_dict['adjacency_matrix']  \n",
    "\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    print( 'TPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print( 'FPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print('SHD:', sum(all_shds)/len(all_shds))\n",
    "    print( 'Accuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print( 'Precision:', sum(all_precisions)/len(all_precisions))\n",
    "    print( 'F1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n",
    "    basic_all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"basic\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            basic_all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    for matrix in basic_all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        basic_all_tprs.append(tpr)\n",
    "        basic_all_fprs.append(fpr)\n",
    "        basic_all_shds.append(shd)\n",
    "        basic_all_accuracies.append(accuracy)\n",
    "        basic_all_precisions.append(precision)\n",
    "        basic_all_F1s.append(f1)\n",
    "    print('TPR:', sum(basic_all_tprs)/len(basic_all_tprs))\n",
    "    print('FPR:', sum(basic_all_fprs)/len(basic_all_fprs))\n",
    "    print('SHD:', sum(basic_all_shds)/len(basic_all_shds))\n",
    "    print('Accuracy:', sum(basic_all_accuracies)/len(basic_all_accuracies))\n",
    "    print('Precision:', sum(basic_all_precisions)/len(basic_all_precisions))\n",
    "    print('F1:', sum(basic_all_F1s)/len(basic_all_F1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:21<00:00, 10.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.2] \n",
      "TPR: 0.2\n",
      "[0.09090909090909091, 0.18181818181818182] \n",
      "FPR: 0.13636363636363635\n",
      "[5, 6] \n",
      "SHD: 5.5\n",
      "[0.6875, 0.625] \n",
      "Accuracy: 0.65625\n",
      "[0.5, 0.3333333333333333] \n",
      "Precision: 0.41666666666666663\n",
      "[0.2, 0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.2, 0.2] \n",
      "Recall: 0.17777777777777776\n",
      "[0.28571428571428575, 0.25] \n",
      "F1: 0.2678571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:13<00:26, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: invalid syntax (<string>, line 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:34<00:17, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Matrix not found in the response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:43<00:00, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 0.2\n",
      "FPR: 0.09090909090909091\n",
      "SHD: 5.0\n",
      "Accuracy: 0.6875\n",
      "Precision: 0.5\n",
      "F1: 0.28571428571428575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h4_100x256/\"\n",
    "    scene_info_dict = scene.get_scene(\"4_V\")\n",
    "    \n",
    "    \n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_f1s = []\n",
    "\n",
    "    basic_all_tprs = []\n",
    "    basic_all_fprs = []\n",
    "    basic_all_shds = []\n",
    "    basic_all_precisions = []\n",
    "    basic_all_accuracies = []\n",
    "    \n",
    "    basic_all_F1s = []      \n",
    "\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    ground_truth = scene_info_dict['adjacency_matrix']  \n",
    "\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    print( 'TPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print( 'FPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print('SHD:', sum(all_shds)/len(all_shds))\n",
    "    print( 'Accuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print( 'Precision:', sum(all_precisions)/len(all_precisions))\n",
    "    print( 'F1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n",
    "    basic_all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"basic\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            basic_all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    for matrix in basic_all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        basic_all_tprs.append(tpr)\n",
    "        basic_all_fprs.append(fpr)\n",
    "        basic_all_shds.append(shd)\n",
    "        basic_all_accuracies.append(accuracy)\n",
    "        basic_all_precisions.append(precision)\n",
    "        basic_all_F1s.append(f1)\n",
    "    print('TPR:', sum(basic_all_tprs)/len(basic_all_tprs))\n",
    "    print('FPR:', sum(basic_all_fprs)/len(basic_all_fprs))\n",
    "    print('SHD:', sum(basic_all_shds)/len(basic_all_shds))\n",
    "    print('Accuracy:', sum(basic_all_accuracies)/len(basic_all_accuracies))\n",
    "    print('Precision:', sum(basic_all_precisions)/len(basic_all_precisions))\n",
    "    print('F1:', sum(basic_all_F1s)/len(basic_all_F1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h2_nonlinear_128P/\"\n",
    "    scene_info_dict = scene.get_scene(\"2_V_nonlinear\")\n",
    "    \n",
    "    \n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_f1s = []\n",
    "\n",
    "    basic_all_tprs = []\n",
    "    basic_all_fprs = []\n",
    "    basic_all_shds = []\n",
    "    basic_all_precisions = []\n",
    "    basic_all_accuracies = []\n",
    "    \n",
    "    basic_all_F1s = []      \n",
    "\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    ground_truth = scene_info_dict['adjacency_matrix']  \n",
    "\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_f1s.append(f1)\n",
    "    print(\"explicted\")\n",
    "    print( 'TPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print( 'FPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print('SHD:', sum(all_shds)/len(all_shds))\n",
    "    print( 'Accuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print( 'Precision:', sum(all_precisions)/len(all_precisions))\n",
    "    print( 'F1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n",
    "    basic_all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"basic\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            basic_all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    for matrix in basic_all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        basic_all_tprs.append(tpr)\n",
    "        basic_all_fprs.append(fpr)\n",
    "        basic_all_shds.append(shd)\n",
    "        basic_all_accuracies.append(accuracy)\n",
    "        basic_all_precisions.append(precision)\n",
    "        basic_all_F1s.append(f1)\n",
    "    print(\"\\nbasic\")\n",
    "    print('TPR:', sum(basic_all_tprs)/len(basic_all_tprs))\n",
    "    print('FPR:', sum(basic_all_fprs)/len(basic_all_fprs))\n",
    "    print('SHD:', sum(basic_all_shds)/len(basic_all_shds))\n",
    "    print('Accuracy:', sum(basic_all_accuracies)/len(basic_all_accuracies))\n",
    "    print('Precision:', sum(basic_all_precisions)/len(basic_all_precisions))\n",
    "    print('F1:', sum(basic_all_F1s)/len(basic_all_F1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:09<00:00,  9.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "TPR: 0.08333333333333333\n",
      "FPR: 0.0\n",
      "SHD: 2.75\n",
      "Accuracy: 0.6944444444444444\n",
      "Precision: 0.2\n",
      "Recall: 0.06666666666666667\n",
      "F1: 0.11499999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:58<00:00,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "basic\n",
      "TPR: 0.05\n",
      "FPR: 0.0\n",
      "SHD: 2.85\n",
      "Accuracy: 0.6833333333333332\n",
      "Precision: 0.1\n",
      "F1: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h3_nonlinear_1_128P/\"\n",
    "    scene_info_dict = scene.get_scene(\"3_V_nonlinear_1\")\n",
    "    \n",
    "    \n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_f1s = []\n",
    "\n",
    "    basic_all_tprs = []\n",
    "    basic_all_fprs = []\n",
    "    basic_all_shds = []\n",
    "    basic_all_precisions = []\n",
    "    basic_all_accuracies = []\n",
    "    \n",
    "    basic_all_F1s = []      \n",
    "\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    ground_truth = scene_info_dict['adjacency_matrix']  \n",
    "\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_f1s.append(f1)\n",
    "    print(\"explicted\")\n",
    "    print( 'TPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print( 'FPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print('SHD:', sum(all_shds)/len(all_shds))\n",
    "    print( 'Accuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print( 'Precision:', sum(all_precisions)/len(all_precisions))\n",
    "    print( 'F1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n",
    "    basic_all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"basic\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            basic_all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    for matrix in basic_all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        basic_all_tprs.append(tpr)\n",
    "        basic_all_fprs.append(fpr)\n",
    "        basic_all_shds.append(shd)\n",
    "        basic_all_accuracies.append(accuracy)\n",
    "        basic_all_precisions.append(precision)\n",
    "        basic_all_F1s.append(f1)\n",
    "    print(\"\\nbasic\")\n",
    "    print('TPR:', sum(basic_all_tprs)/len(basic_all_tprs))\n",
    "    print('FPR:', sum(basic_all_fprs)/len(basic_all_fprs))\n",
    "    print('SHD:', sum(basic_all_shds)/len(basic_all_shds))\n",
    "    print('Accuracy:', sum(basic_all_accuracies)/len(basic_all_accuracies))\n",
    "    print('Precision:', sum(basic_all_precisions)/len(basic_all_precisions))\n",
    "    print('F1:', sum(basic_all_F1s)/len(basic_all_F1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:26<08:30, 26.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: invalid syntax (<string>, line 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:52<00:00, 11.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicted\n",
      "TPR: 0.07017543859649122\n",
      "FPR: 0.012145748987854251\n",
      "SHD: 2.9473684210526314\n",
      "Accuracy: 0.8157894736842105\n",
      "Precision: 0.21052631578947367\n",
      "F1: 0.10526315789473684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:25<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "basic\n",
      "TPR: 0.11666666666666665\n",
      "FPR: 0.011538461538461539\n",
      "SHD: 2.8\n",
      "Accuracy: 0.825\n",
      "Precision: 0.3\n",
      "F1: 0.16499999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h4_128x128_nonlinear/\"\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "    scene_info_dict = scene.get_scene(\"4_V_nonlinear\")\n",
    "    \n",
    "    \n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_f1s = []\n",
    "\n",
    "    basic_all_tprs = []\n",
    "    basic_all_fprs = []\n",
    "    basic_all_shds = []\n",
    "    basic_all_precisions = []\n",
    "    basic_all_accuracies = []\n",
    "    \n",
    "    basic_all_F1s = []      \n",
    "\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    ground_truth = scene_info_dict['adjacency_matrix']  \n",
    "\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_f1s.append(f1)\n",
    "    print(\"explicted\")\n",
    "    print( 'TPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print( 'FPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print('SHD:', sum(all_shds)/len(all_shds))\n",
    "    print( 'Accuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print( 'Precision:', sum(all_precisions)/len(all_precisions))\n",
    "    print( 'F1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n",
    "    basic_all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"basic\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            basic_all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    for matrix in basic_all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        basic_all_tprs.append(tpr)\n",
    "        basic_all_fprs.append(fpr)\n",
    "        basic_all_shds.append(shd)\n",
    "        basic_all_accuracies.append(accuracy)\n",
    "        basic_all_precisions.append(precision)\n",
    "        basic_all_F1s.append(f1)\n",
    "    print(\"\\nbasic\")\n",
    "    print('TPR:', sum(basic_all_tprs)/len(basic_all_tprs))\n",
    "    print('FPR:', sum(basic_all_fprs)/len(basic_all_fprs))\n",
    "    print('SHD:', sum(basic_all_shds)/len(basic_all_shds))\n",
    "    print('Accuracy:', sum(basic_all_accuracies)/len(basic_all_accuracies))\n",
    "    print('Precision:', sum(basic_all_precisions)/len(basic_all_precisions))\n",
    "    print('F1:', sum(basic_all_F1s)/len(basic_all_F1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_causal_matrix() got an unexpected keyword argument 'scene_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mget_causal_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_base64_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mscene_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscene_info_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdump\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_causal_matrix() got an unexpected keyword argument 'scene_info'"
     ]
    }
   ],
   "source": [
    "matrix = get_causal_matrix(client, image_base64_list,\n",
    "                                       scene_info=scene_info_dict, dump=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 155057.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "Error: get_causal_matrix() got an unexpected keyword argument 'prompt_type'\n",
      "explicted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m     all_f1s\u001b[38;5;241m.\u001b[39mappend(f1)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPR:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_tprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_tprs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPR:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28msum\u001b[39m(all_fprs)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_fprs))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHD:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28msum\u001b[39m(all_shds)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_shds))\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    client = OpenAI(api_key=api_key)  # this is also the default, it can be omitted)\n",
    "    image_dir = \"/home/lds/github/Causality-informed-Generation/code1/database/rendered_h5_150x150_nonlinear/\"\n",
    "    sys.path.append('/home/lds/github/Causality-informed-Generation/inference/evaluation')\n",
    "    from utils import info\n",
    "\n",
    "    scene = info.scene()\n",
    "    scene_info_dict = scene.get_scene(\"5_V_nonlinear\")\n",
    "    \n",
    "    \n",
    "    images, encoded_imgs = get_images(image_dir, 10)\n",
    "    image_base64_list = encoded_imgs\n",
    "    all_results = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_tprs = []\n",
    "    all_fprs = []\n",
    "    all_shds = []\n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_f1s = []\n",
    "\n",
    "    basic_all_tprs = []\n",
    "    basic_all_fprs = []\n",
    "    basic_all_shds = []\n",
    "    basic_all_precisions = []\n",
    "    basic_all_accuracies = []\n",
    "    \n",
    "    basic_all_F1s = []      \n",
    "\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"explicted\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "    ground_truth = scene_info_dict['adjacency_matrix']  \n",
    "\n",
    "    for matrix in all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        recall = cal_Recall_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        all_tprs.append(tpr)\n",
    "        all_fprs.append(fpr)\n",
    "        all_shds.append(shd)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_f1s.append(f1)\n",
    "    print(\"explicted\")\n",
    "    print( 'TPR:', sum(all_tprs)/len(all_tprs))\n",
    "    print( 'FPR:', sum(all_fprs)/len(all_fprs))\n",
    "    print('SHD:', sum(all_shds)/len(all_shds))\n",
    "    print( 'Accuracy:', sum(all_accuracies)/len(all_accuracies))\n",
    "    print( 'Precision:', sum(all_precisions)/len(all_precisions))\n",
    "    print( 'F1:', sum(all_f1s)/len(all_f1s))\n",
    "    \n",
    "    basic_all_results = []\n",
    "    for i in tqdm(range(20)):\n",
    "        try:\n",
    "            matrix = get_causal_matrix(client, image_base64_list, prompt_type=\"basic\",\n",
    "                                       scene_info=scene_info_dict, dump=True)\n",
    "            # print(\"Causal Adjacency Matrix:\")\n",
    "            # print(matrix)\n",
    "            basic_all_results.append(matrix)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "    for matrix in basic_all_results:\n",
    "        matrix = np.array(matrix)\n",
    "        tpr = cal_TPR_between_matrix(ground_truth, matrix)\n",
    "        fpr = cal_FPR_between_matrix(ground_truth, matrix)\n",
    "        shd = cal_SHD_between_matrix(ground_truth, matrix)\n",
    "        accuracy = cal_Accuarcy_between_matrix(ground_truth, matrix)\n",
    "        precision = cal_Precision_between_matrix(ground_truth, matrix)\n",
    "        f1 = cal_F1_between_matrix(ground_truth, matrix)\n",
    "        \n",
    "        basic_all_tprs.append(tpr)\n",
    "        basic_all_fprs.append(fpr)\n",
    "        basic_all_shds.append(shd)\n",
    "        basic_all_accuracies.append(accuracy)\n",
    "        basic_all_precisions.append(precision)\n",
    "        basic_all_F1s.append(f1)\n",
    "    print(\"\\nbasic\")\n",
    "    print('TPR:', sum(basic_all_tprs)/len(basic_all_tprs))\n",
    "    print('FPR:', sum(basic_all_fprs)/len(basic_all_fprs))\n",
    "    print('SHD:', sum(basic_all_shds)/len(basic_all_shds))\n",
    "    print('Accuracy:', sum(basic_all_accuracies)/len(basic_all_accuracies))\n",
    "    print('Precision:', sum(basic_all_precisions)/len(basic_all_precisions))\n",
    "    print('F1:', sum(basic_all_F1s)/len(basic_all_F1s))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
